{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0hVNAozgzJm"
      },
      "source": [
        "# **1. Demo Básica de Retrieval-Augmented Generation (BasicRAG) con Gemini:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeijQZB2qbFn"
      },
      "source": [
        "## ¿Cómo funciona?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8VqoaXmgsgX"
      },
      "source": [
        "En este ejemplo veremos cómo funciona un sistema básico de RAG (Retrieval-Augmented Generation).\n",
        "La idea principal es:\n",
        "\n",
        "1. Subir un documento de texto (ejemplo: un archivo con información de física cuántica o historia).\n",
        "\n",
        "2. Dividir el documento en fragmentos pequeños (chunks).\n",
        "\n",
        "3. Convertir esos fragmentos en embeddings (vectores numéricos que representan el significado del texto).\n",
        "\n",
        "4. Guardar los embeddings en una base de datos vectorial (ChromaDB).\n",
        "\n",
        "5. Hacer una pregunta en lenguaje natural → el sistema busca los fragmentos más relevantes.\n",
        "\n",
        "6. Gemini responde usando esos fragmentos como contexto, para dar una respuesta más precisa y confiable.\n",
        "\n",
        "Esto es lo que hace especial a RAG: el modelo no depende solo de su memoria entrenada, sino que consulta información externa que nosotros le damos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7VmJZQKqtlO"
      },
      "source": [
        "## **Preparación del entorno:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vc0XyXyqxZu"
      },
      "source": [
        "**Antes de ejecutar el código:**\n",
        "\n",
        "1. **Obtener tu API Key de Gemini:**\n",
        "\n",
        "- Entra a 👉 Google AI Studio: https://aistudio.google.com/.\n",
        "\n",
        "- Crea una clave desde la sección API Keys.\n",
        "\n",
        "- Copia tu API Key y reemplaza en la línea: **os.environ[\"GEMINI_API_KEY\"] = \"TU_API_KEY_AQUI\"**\n",
        "\n",
        "\n",
        "**Este paso solo es necesario si la que está puesta falla, o si cada estudiante quiere usar su propia clave.**\n",
        "\n",
        "2. **Archivos de prueba disponibles en Drive (Debajo se indican los documentos utilizados en la demo en calse): https://drive.google.com/drive/folders/1uF7-oSMpzSdID2ltQf9NsU5Snf16fHfx?usp=sharing**\n",
        "\n",
        "- cuantica.txt → introducción a la física cuántica. **(Usado en al demo en clase)**.\n",
        "\n",
        "- innovadores.txt → introducción a la física cuántica. **(Usado en al demo en clase)**.\n",
        "\n",
        "- historia_Colombia.txt → texto sobre historia de Colombia.\n",
        "\n",
        "- historia_internet.txt → documento con explicación básica de Einstein.\n",
        "\n",
        "👉 **Suban uno de estos archivos (o el suyo propio) cuando el código lo pida.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate==0.4.5\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "J9q_nPxVGRxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6969c6d7-e78a-4a72-fd35-ea6fe42f16f3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate==0.4.5 in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.5) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.5) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.5) (1.17.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clo-IDEYWys-",
        "outputId": "53972817-4415-41b7-edc6-9c93b38a2327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.182.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=ba5c6bdeffaa2b0dd2b99ea79c66a4da5b72a4e01beab8091c657f2d640fd4b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# ================= DEMO RAG CON GEMINI ==================\n",
        "!pip install chromadb sentence-transformers google-generativeai\n",
        "\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 1. CONFIGURACIÓN DE GEMINI =========\n",
        "# 👉 Paso previo: obtener API Key en https://aistudio.google.com/\n",
        "#  Cambia tu API Key SOLO si la actual no funciona.\n",
        "from google.colab import userdata\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('gemini')\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "lz8oh3LUZXBK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 2. SUBIR ARCHIVO =========\n",
        "print(\"Sube un archivo de texto con información (ej: cuantica.txt)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "FpgCoeChZZVS",
        "outputId": "9c6238d4-7c12-4226-d8f9-da384420701a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube un archivo de texto con información (ej: cuantica.txt)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-88a88125-7569-4c55-b54d-a5b1692dce70\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-88a88125-7569-4c55-b54d-a5b1692dce70\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1834540293.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ========= 2. SUBIR ARCHIVO =========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sube un archivo de texto con información (ej: cuantica.txt)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 3. FUNCIÓN DE CHUNKING =========\n",
        "def chunk_text(text, chunk_size=80, overlap=20):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunk = \" \".join(words[i:i+chunk_size])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "docs = chunk_text(text, chunk_size=80, overlap=20)\n",
        "\n",
        "print(\"Ejemplo de 3 chunks creados:\")\n",
        "for c in docs[:3]:\n",
        "    print(\"-\", c, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_XL00sOZhnE",
        "outputId": "221380c2-49c0-4a5c-b9eb-3c84fdd3eed6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de 3 chunks creados:\n",
            "- Elon Musk fundó Tesla, una compañía dedicada a la fabricación de automóviles eléctricos y soluciones de energía renovable. También fundó SpaceX, una empresa de exploración espacial que desarrolla cohetes y satélites. Además, participó en la creación de PayPal, un sistema de pagos en línea que revolucionó las transacciones digitales. Steve Jobs fue cofundador de Apple, empresa reconocida por sus productos tecnológicos innovadores como el iPhone, iPad y MacBook. Apple ha sido clave en el desarrollo de la industria de los \n",
            "\n",
            "- tecnológicos innovadores como el iPhone, iPad y MacBook. Apple ha sido clave en el desarrollo de la industria de los dispositivos inteligentes. Jeff Bezos fundó Amazon, inicialmente como una librería en línea, que evolucionó hacia una de las mayores plataformas de comercio electrónico y servicios en la nube a través de Amazon Web Services (AWS). Mark Zuckerberg creó Facebook, una red social que transformó la comunicación digital, la publicidad y la interacción en línea. Larry Page y Sergey Brin fundaron \n",
            "\n",
            "- red social que transformó la comunicación digital, la publicidad y la interacción en línea. Larry Page y Sergey Brin fundaron Google, un motor de búsqueda que cambió el acceso a la información global. Google también desarrolló Android, el sistema operativo más utilizado en teléfonos inteligentes. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 4. CREAR EMBEDDINGS Y BASE VECTORIAL =========\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "client = chromadb.Client()\n",
        "collection = client.get_or_create_collection(\"physics_chunks\")\n",
        "\n",
        "embeddings = embedder.encode(docs).tolist()\n",
        "for i, d in enumerate(docs):\n",
        "    collection.add(documents=[d], embeddings=[embeddings[i]], ids=[str(i)])\n",
        "\n"
      ],
      "metadata": {
        "id": "RcIzv2tYZbtk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 5. CONSULTA Y RETRIEVAL =========\n",
        "# 👉 Aquí puedes cambiar la pregunta y experimentar ========================================\n",
        "# Ejemplos para probar:\n",
        "# query = \"¿Qué explica la teoría de la relatividad?\"\n",
        "# query = \"¿Cuál fue un hecho clave en la independencia de Colombia?\"\n",
        "query = \"¿Qué científico propuso un modelo atómico en 1913?\"\n",
        "q_embed = embedder.encode([query]).tolist()\n",
        "results = collection.query(query_embeddings=q_embed, n_results=3)\n",
        "retrieved_context = \" \".join(results['documents'][0])\n",
        "\n",
        "print(\"\\n🔹 Chunks relevantes recuperados:\")\n",
        "for doc in results['documents'][0]:\n",
        "    print(\"-\", doc)\n",
        "\n",
        "print(\"\\n🔹 Contexto recuperado:\")\n",
        "print(retrieved_context)"
      ],
      "metadata": {
        "id": "6FwLXClZZdOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f4c3a5-fa3b-44bc-c22e-1b4389181c35"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Chunks relevantes recuperados:\n",
            "- Max Planck introdujo en 1900 la idea de que la energía no se emite de manera continua, sino en cuantos discretos. Este fue el inicio de la teoría cuántica. Albert Einstein en 1905 explicó el efecto fotoeléctrico utilizando el concepto de cuantos de luz, lo que posteriormente llamó fotones. Niels Bohr en 1913 propuso su modelo atómico, donde los electrones orbitaban en niveles de energía cuantizados alrededor del núcleo. Werner Heisenberg enunció en 1927 el principio de incertidumbre, que indica\n",
            "- orbitaban en niveles de energía cuantizados alrededor del núcleo. Werner Heisenberg enunció en 1927 el principio de incertidumbre, que indica que no es posible conocer con precisión la posición y el momento de una partícula al mismo tiempo. Erwin Schrödinger desarrolló la ecuación de onda en 1926, fundamental para describir el comportamiento cuántico de las partículas. Richard Feynman contribuyó a la electrodinámica cuántica y popularizó el uso de diagramas que llevan su nombre.\n",
            "- la electrodinámica cuántica y popularizó el uso de diagramas que llevan su nombre.\n",
            "\n",
            "🔹 Contexto recuperado:\n",
            "Max Planck introdujo en 1900 la idea de que la energía no se emite de manera continua, sino en cuantos discretos. Este fue el inicio de la teoría cuántica. Albert Einstein en 1905 explicó el efecto fotoeléctrico utilizando el concepto de cuantos de luz, lo que posteriormente llamó fotones. Niels Bohr en 1913 propuso su modelo atómico, donde los electrones orbitaban en niveles de energía cuantizados alrededor del núcleo. Werner Heisenberg enunció en 1927 el principio de incertidumbre, que indica orbitaban en niveles de energía cuantizados alrededor del núcleo. Werner Heisenberg enunció en 1927 el principio de incertidumbre, que indica que no es posible conocer con precisión la posición y el momento de una partícula al mismo tiempo. Erwin Schrödinger desarrolló la ecuación de onda en 1926, fundamental para describir el comportamiento cuántico de las partículas. Richard Feynman contribuyó a la electrodinámica cuántica y popularizó el uso de diagramas que llevan su nombre. la electrodinámica cuántica y popularizó el uso de diagramas que llevan su nombre.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 6. GEMINI PARA RESPONDER CON CONTEXTO =========\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
        "\n",
        "response = model.generate_content(\n",
        "    f\"UBasándote en el siguiente contexto, responde la pregunta y añade una breve explicación adicional desde tu conocimiento si es relevante:.\\n\\nContexto:\\n{retrieved_context}\\n\\nPregunta: {query}\"\n",
        ")\n",
        "\n",
        "response_no_context = model.generate_content(\n",
        "    f\"UBasándote en el siguiente contexto, responde la pregunta y añade una breve explicación adicional desde tu conocimiento si es relevante:.\\n\\nPregunta: {query}\"\n",
        ")\n",
        "\n",
        "response_chat = \"El científico que propuso un modelo atómico en **1913 fue Niels Bohr**. Bohr planteó que los electrones orbitan alrededor del núcleo en niveles de energía cuantizados, lo que permitió explicar fenómenos como las líneas espectrales del hidrógeno. Este modelo fue un gran avance respecto al de Rutherford, ya que incorporó ideas de la teoría cuántica para describir la estabilidad del átomo. De manera adicional, aunque luego fue superado por la mecánica cuántica de Schrödinger y Heisenberg, el modelo de Bohr sigue siendo muy útil en la enseñanza porque introduce de forma sencilla el concepto de niveles de energía y la transición de electrones con emisión o absorción de fotones.\"\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada por Gemini:\")\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada por Gemini sin contexto:\")\n",
        "print(response_no_context.text)\n",
        "\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada por Chatgpt:\")\n",
        "print(response_chat)"
      ],
      "metadata": {
        "id": "JEhZG15cZfDU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "fdcb0172-8cc2-4256-b4d5-696da1cd4d0e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Respuesta generada por Gemini:\n",
            "Niels Bohr propuso un modelo atómico en 1913.  Este modelo incorporaba la idea de cuantización de la energía, postulada previamente por Planck, para explicar la estabilidad del átomo y las líneas espectrales del hidrógeno.  A diferencia de los modelos atómicos anteriores, el de Bohr planteaba que los electrones orbitaban el núcleo en niveles de energía discretos y definidos, y que la emisión o absorción de energía ocurría cuando un electrón saltaba entre estos niveles.  Si bien este modelo tenía limitaciones y fue posteriormente superado por la mecánica cuántica, fue un paso crucial en la comprensión de la estructura atómica.\n",
            "\n",
            "\n",
            "🔹 Respuesta generada por Gemini sin contexto:\n",
            "Niels Bohr propuso un modelo atómico en 1913.\n",
            "\n",
            "**Explicación adicional:** El modelo atómico de Bohr mejoró significativamente el modelo de Rutherford al incorporar la teoría cuántica de Planck.  A diferencia del modelo de Rutherford, que dejaba sin explicar la estabilidad de los átomos (los electrones deberían caer en espiral hacia el núcleo), Bohr postuló que los electrones orbitan el núcleo en niveles de energía específicos y cuantizados.  Solo pueden existir en estas órbitas definidas y  absorben o emiten energía al saltar entre ellas. Este modelo, aunque posteriormente fue reemplazado por modelos más complejos y precisos (como la mecánica cuántica), fue un paso crucial en la comprensión de la estructura atómica y sentó las bases para futuros desarrollos en la física atómica y la química cuántica.\n",
            "\n",
            "\n",
            "🔹 Respuesta generada por Chatgpt:\n",
            "El científico que propuso un modelo atómico en **1913 fue Niels Bohr**. Bohr planteó que los electrones orbitan alrededor del núcleo en niveles de energía cuantizados, lo que permitió explicar fenómenos como las líneas espectrales del hidrógeno. Este modelo fue un gran avance respecto al de Rutherford, ya que incorporó ideas de la teoría cuántica para describir la estabilidad del átomo. De manera adicional, aunque luego fue superado por la mecánica cuántica de Schrödinger y Heisenberg, el modelo de Bohr sigue siendo muy útil en la enseñanza porque introduce de forma sencilla el concepto de niveles de energía y la transición de electrones con emisión o absorción de fotones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Métricas de evaluación"
      ],
      "metadata": {
        "id": "jd0d13ZvGXGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "\n",
        "def evaluate_response(response, reference_response):\n",
        "  # Generated response from Gemini with context\n",
        "  generated_response_context = response.text\n",
        "  # Reference response from chatgpt\n",
        "  reference_response = response_chat\n",
        "\n",
        "  # Calculate BLEU score for context\n",
        "  bleu = load(\"bleu\")\n",
        "  bleu_score_context = bleu.compute(predictions=[generated_response_context], references=[reference_response])\n",
        "  print(f\"\\n🔹 BLEU score (Gemini with context): {bleu_score_context['bleu']:.4f}\")\n",
        "  print(\"🔹 BLEU precision scores (Gemini with context):\")\n",
        "  for i, precision in enumerate(bleu_score_context['precisions']):\n",
        "      print(f\"- Precision@{i+1}: {precision:.4f}\")\n",
        "\n",
        "  # Calculate ROUGE score for context\n",
        "  rouge = load(\"rouge\")\n",
        "  rouge_score_context = rouge.compute(predictions=[generated_response_context], references=[reference_response])\n",
        "  print(\"\\n🔹 ROUGE score (Gemini with context):\")\n",
        "  for key, value in rouge_score_context.items():\n",
        "      print(f\"- {key}: {value:.4f}\")\n",
        "\n",
        "  return bleu_score_context, rouge_score_context"
      ],
      "metadata": {
        "id": "Re55YnZP6SY_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_response_no_context(response, reference_response):\n",
        "  # Generated response from Gemini with no context\n",
        "  generated_response_no_context = response_no_context.text\n",
        "  # Reference response from chatgpt\n",
        "  reference_response = response_chat\n",
        "\n",
        "  # Calculate BLEU score for no context\n",
        "  bleu = load(\"bleu\")\n",
        "  bleu_score_no_context = bleu.compute(predictions=[generated_response_no_context], references=[reference_response])\n",
        "  print(f\"\\n🔹 BLEU score (Gemini without context): {bleu_score_no_context['bleu']:.4f}\")\n",
        "\n",
        "  # Calculate ROUGE score for no context\n",
        "  rouge = load(\"rouge\")\n",
        "  rouge_score_no_context = rouge.compute(predictions=[generated_response_no_context], references=[reference_response])\n",
        "  print(\"\\n🔹 ROUGE score (Gemini without context):\")\n",
        "  for key, value in rouge_score_no_context.items():\n",
        "      print(f\"- {key}: {value:.4f}\")\n",
        "\n",
        "  return bleu_score_no_context, rouge_score_no_context"
      ],
      "metadata": {
        "id": "IFWcF9eP-1x5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "877e8005",
        "outputId": "4f52f72e-051f-4698-d5e8-694623ebeb60"
      },
      "source": [
        "# ========= 8. COMPARACIÓN E INTERPRETACIÓN DE RESULTADOS =========\n",
        "\n",
        "print(\"\\n=== Comparación e Interpretación de las Métricas ===\")\n",
        "\n",
        "print(\"\\nComparando las respuestas generadas con la referencia (ChatGPT):\")\n",
        "\n",
        "bue_score_context, rouge_score_context = evaluate_response(response, response_chat)\n",
        "bue_score_no_context, rouge_score_no_context = evaluate_response_no_context(response_no_context, response_chat)\n",
        "\n",
        "# Compare BLEU scores\n",
        "print(\"\\nResultados BLEU:\")\n",
        "print(f\"- Gemini con contexto (BLEU): {bleu_score_context['bleu']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (BLEU): {bleu_score_no_context['bleu']:.4f}\")\n",
        "\n",
        "if bleu_score_context['bleu'] > bleu_score_no_context['bleu']:\n",
        "    print(\"  -> Según el BLEU score general, la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif bleu_score_context['bleu'] < bleu_score_no_context['bleu']:\n",
        "     print(\"  -> Según el BLEU score general, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los BLEU scores generales son similares.\")\n",
        "\n",
        "print(\"\\nResultados ROUGE:\")\n",
        "print(f\"- Gemini con contexto (ROUGE-1): {rouge_score_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-1): {rouge_score_no_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini con contexto (ROUGE-L): {rouge_score_context['rougeL']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-L): {rouge_score_no_context['rougeL']:.4f}\")\n",
        "\n",
        "\n",
        "if rouge_score_context['rouge1'] > rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> Según ROUGE-1 (superposición de palabras individuales), la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif rouge_score_context['rouge1'] < rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> Según ROUGE-1, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los ROUGE-1 scores son similares.\")\n",
        "\n",
        "if rouge_score_context['rougeL'] > rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> Según ROUGE-L (subsecuencia más larga, sensible al orden), la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif rouge_score_context['rougeL'] < rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> Según ROUGE-L, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "     print(\"  -> Los ROUGE-L scores son similares.\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Comparación e Interpretación de las Métricas ===\n",
            "\n",
            "Comparando las respuestas generadas con la referencia (ChatGPT):\n",
            "\n",
            "🔹 BLEU score (Gemini with context): 0.0000\n",
            "🔹 BLEU precision scores (Gemini with context):\n",
            "- Precision@1: 0.0737\n",
            "- Precision@2: 0.0080\n",
            "- Precision@3: 0.0000\n",
            "- Precision@4: 0.0000\n",
            "\n",
            "🔹 ROUGE score (Gemini with context):\n",
            "- rouge1: 0.1957\n",
            "- rouge2: 0.0164\n",
            "- rougeL: 0.1196\n",
            "- rougeLsum: 0.1359\n",
            "\n",
            "🔹 BLEU score (Gemini without context): 0.1400\n",
            "\n",
            "🔹 ROUGE score (Gemini without context):\n",
            "- rouge1: 0.5387\n",
            "- rouge2: 0.2751\n",
            "- rougeL: 0.2731\n",
            "- rougeLsum: 0.2731\n",
            "\n",
            "Resultados BLEU:\n",
            "- Gemini con contexto (BLEU): 0.0904\n",
            "- Gemini sin contexto (BLEU): 0.0896\n",
            "  -> Según el BLEU score general, la respuesta de Gemini con contexto es más similar a la referencia.\n",
            "\n",
            "Resultados ROUGE:\n",
            "- Gemini con contexto (ROUGE-1): 0.1957\n",
            "- Gemini sin contexto (ROUGE-1): 0.5387\n",
            "- Gemini con contexto (ROUGE-L): 0.1196\n",
            "- Gemini sin contexto (ROUGE-L): 0.2731\n",
            "  -> Según ROUGE-1, la respuesta de Gemini sin contexto es más similar a la referencia.\n",
            "  -> Según ROUGE-L, la respuesta de Gemini sin contexto es más similar a la referencia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyQtSj8YhcW3"
      },
      "source": [
        "# 2. **GraphRAG con Gemini + Neo4j: Consultando Grafos de Conocimiento:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tkzFK1bhYG7"
      },
      "source": [
        "En este ejemplo usamos Gemini para extraer triples semánticos del texto (por ejemplo: (Elon Musk, fundó, Tesla)).\n",
        "\n",
        "Luego esos triples se guardan en Neo4j, una base de datos orientada a grafos.\n",
        "Después, podemos hacer consultas usando Cypher, el lenguaje de Neo4j, y finalmente Gemini genera una respuesta en lenguaje natural usando la información consultada.\n",
        "\n",
        "Esto permite transformar un texto plano en un grafo de conocimiento consultable, lo que es muy útil para preguntas complejas que requieren relaciones entre entidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiMLgjeuvQqs"
      },
      "source": [
        "## **Preparación del entorno:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EDSiOHMvROs"
      },
      "source": [
        "Antes de ejecutar el código:\n",
        "\n",
        "1. **Cuenta en Neo4j AuraDB (gratis): https://neo4j.com/product/auradb/**\n",
        "\n",
        "- Ir a Neo4j AuraDB Free.\n",
        "\n",
        "- Crear una cuenta y una base de datos gratuita.\n",
        "\n",
        "- Copiar los datos de conexión (URI, Usuario, Contraseña).\n",
        "\n",
        "**⚠️ Este paso, al igual que la creación de la API Key de Gemini, solo será necesario si las credenciales ya incluidas en el código no funcionan.\n",
        "De esta manera, cada estudiante tendrá la opción de usar sus propias credenciales y su propia base de datos personalizada en caso de que sea necesario.**\n",
        "\n",
        "2. **Nuevamente tener presente los archivos disponibles en Drive:https://drive.google.com/drive/folders/1uF7-oSMpzSdID2ltQf9NsU5Snf16fHfx?usp=sharing**\n",
        "\n",
        "- cuantica.txt → introducción a la física cuántica. **(Usado en al demo en clase)**.\n",
        "\n",
        "- innovadores.txt → introducción a la física cuántica. **(Usado en al demo en clase)**.\n",
        "\n",
        "- historia_Colombia.txt → texto sobre historia de Colombia.\n",
        "\n",
        "- historia_internet.txt → documento con explicación básica de Einstein.\n",
        "\n",
        "👉 **Suban uno de estos archivos (o el suyo propio) cuando el código lo pida.****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46Y4MlqqwSv5"
      },
      "source": [
        "## **Snippets de Cypher para practicar**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpIzHKKVwl-Q"
      },
      "source": [
        "Los estudiantes pueden reemplazar el query y la pregunta con estos ejemplos (COPIAR Y PEGAR EN EL BLOQUE DE CODIGO DEL GRAPHRAG):\n",
        "\n",
        "### **Para el documento innovadores.txt disponible en google drive:** ¿Cuáles son las empresas fundadas por Elon Musk y por Steve Jobs, a qué se dedica cada una y por qué es importante lo que hacen?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "EZ-LhlWxxJMv"
      },
      "outputs": [],
      "source": [
        "cypher_query = \"\"\"\n",
        "MATCH (p:Entidad)-[r:RELACION]->(c:Entidad)\n",
        "RETURN p.name AS persona, r.tipo AS relacion, c.name AS compania\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx_BWVFnyQx2"
      },
      "source": [
        "### **Para el documento hisotria_internet.txt disponible en google drive:** ¿Cuál fue la importancia de Tim Berners-Lee en la historia de Internet?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yqHm3eEwyOeM"
      },
      "outputs": [],
      "source": [
        "cypher_query = \"\"\"\n",
        "MATCH (a:Entidad)-[r:RELACION]->(b:Entidad)\n",
        "WHERE a.name = \"Tim Berners-Lee\"\n",
        "RETURN a.name AS a, r.tipo AS relacion, b.name AS b\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6KFM7pFpghrn",
        "outputId": "7caa7aa5-0ddb-4794-f973-65efa779d4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.12/dist-packages (5.28.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from neo4j) (2025.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.182.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
            "Sube un archivo de texto con información (ej: innovadores.txt)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78ecf771-3df7-44db-b18f-52a7837a6ac1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78ecf771-3df7-44db-b18f-52a7837a6ac1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving innovadores.txt to innovadores (8).txt\n",
            "🔹 Triples extraídos por Gemini:\n",
            "Aquí tienes las relaciones extraídas del texto en formato de triples (SUJETO, RELACIÓN, OBJETO):\n",
            "\n",
            "* (Elon Musk, fundó, Tesla)\n",
            "* (Tesla, tipo_de_compañía, fabricante de automóviles eléctricos)\n",
            "* (Tesla, se_dedica_a, soluciones de energía renovable)\n",
            "* (Elon Musk, fundó, SpaceX)\n",
            "* (SpaceX, tipo_de_empresa, empresa de exploración espacial)\n",
            "* (SpaceX, desarrolla, cohetes)\n",
            "* (SpaceX, desarrolla, satélites)\n",
            "* (Elon Musk, participó_en_la_creación_de, PayPal)\n",
            "* (PayPal, tipo_de_sistema, sistema de pagos en línea)\n",
            "* (PayPal, revolucionó, transacciones digitales)\n",
            "* (Steve Jobs, fue_cofundador_de, Apple)\n",
            "* (Apple, reconocida_por, productos tecnológicos innovadores)\n",
            "* (Apple, desarrolló, iPhone)\n",
            "* (Apple, desarrolló, iPad)\n",
            "* (Apple, desarrolló, MacBook)\n",
            "* (Apple, fue_clave_en, desarrollo de la industria de los dispositivos inteligentes)\n",
            "* (Jeff Bezos, fundó, Amazon)\n",
            "* (Amazon, inicio_como, librería en línea)\n",
            "* (Amazon, evolucionó_hacia, plataforma de comercio electrónico)\n",
            "* (Amazon, ofrece, servicios en la nube)\n",
            "* (Amazon, servicio_en_la_nube, Amazon Web Services (AWS))\n",
            "* (Mark Zuckerberg, creó, Facebook)\n",
            "* (Facebook, tipo_de_red, red social)\n",
            "* (Facebook, transformó, comunicación digital)\n",
            "* (Facebook, transformó, publicidad)\n",
            "* (Facebook, transformó, interacción en línea)\n",
            "* (Larry Page, fundó, Google)\n",
            "* (Sergey Brin, fundó, Google)\n",
            "* (Google, tipo_de_servicio, motor de búsqueda)\n",
            "* (Google, cambió, acceso a la información global)\n",
            "* (Google, desarrolló, Android)\n",
            "* (Android, tipo_de_sistema, sistema operativo)\n",
            "* (Android, uso_en, teléfonos inteligentes)\n",
            "* (Android, sistema_operativo_mas_usado, teléfonos inteligentes)\n",
            "\n",
            "\n",
            "He tratado de ser lo más preciso posible, usando relaciones que reflejen el significado del texto.  Algunas relaciones podrían ser más específicas o detalladas dependiendo del contexto y del nivel de granularidad requerido.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4281262237.py:61: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triple, s, r, o)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Se insertaron 35 triples en Neo4j\n",
            "\n",
            "🔹 Resultados de la consulta Cypher:\n",
            "* **(Elon Musk fundó Tesla)**\n",
            "* **(Tesla tipo_de_compañía fabricante de automóviles eléctricos y soluciones de energía renovable)**\n",
            "* **(Elon Musk fundó SpaceX)**\n",
            "* **(SpaceX tipo_de_empresa empresa de exploración espacial)**\n",
            "* **(SpaceX desarrolla cohetes y satélites)**\n",
            "* **(Elon Musk participó_en_la_creación PayPal)**\n",
            "* **(PayPal tipo_de_servicio sistema de pagos en línea)**\n",
            "* **(Steve Jobs cofundó Apple)**\n",
            "* **(Apple tipo_de_empresa empresa reconocida por sus productos tecnológicos innovadores)**\n",
            "* **(Apple desarrolló iPhone)**\n",
            "* **(Apple desarrolló iPad)**\n",
            "* **(Apple desarrolló MacBook)**\n",
            "* **(Apple clave_en_el_desarrollo industria de los dispositivos inteligentes)**\n",
            "* **(Jeff Bezos fundó Amazon)**\n",
            "* **(Amazon inicio_como librería en línea)**\n",
            "* **(Amazon evolucionó_a plataforma de comercio electrónico y servicios en la nube)**\n",
            "* **(Amazon ofrece Amazon Web Services (AWS))**\n",
            "* **(Mark Zuckerberg creó Facebook)**\n",
            "* **(Facebook tipo_de_plataforma red social)**\n",
            "* **(Facebook transformó comunicación digital)**\n",
            "* **(Facebook transformó publicidad)**\n",
            "* **(Facebook transformó interacción en línea)**\n",
            "* **(Larry Page fundó Google)**\n",
            "* **(Sergey Brin fundó Google)**\n",
            "* **(Google tipo_de_servicio motor de búsqueda)**\n",
            "* **(Google desarrolló Android)**\n",
            "* **(Android tipo_de_sistema sistema operativo)**\n",
            "* **(Android uso teléfonos inteligentes)**\n",
            "* (Elon Musk fundó Tesla\n",
            "* (Tesla es compañía de automóviles eléctricos y soluciones de energía renovable\n",
            "* (Elon Musk fundó SpaceX\n",
            "* (SpaceX es empresa de exploración espacial\n",
            "* (SpaceX tipo_de_empresa empresa de exploración espacial\n",
            "* (SpaceX desarrolla cohetes y satélites\n",
            "* (Elon Musk participó en la creación de PayPal\n",
            "* (Elon Musk participó_en_la_creación_de PayPal\n",
            "* (PayPal es sistema de pagos en línea\n",
            "* (PayPal tipo_de_sistema sistema de pagos en línea\n",
            "* (PayPal revolucionó transacciones digitales\n",
            "* (Steve Jobs fue cofundador de Apple\n",
            "* (Steve Jobs cofundó Apple\n",
            "* (Steve Jobs fue_cofundador_de Apple\n",
            "* (Apple es empresa de productos tecnológicos innovadores\n",
            "* (Apple fue clave en el desarrollo de industria de los dispositivos inteligentes\n",
            "* (Jeff Bezos fundó Amazon\n",
            "* (Amazon fue inicialmente librería en línea\n",
            "* (Amazon inicio_como librería en línea\n",
            "* (Amazon evolucionó hacia plataforma de comercio electrónico y servicios en la nube\n",
            "* (Amazon ofrece Amazon Web Services (AWS\n",
            "* (Amazon servicio Amazon Web Services (AWS\n",
            "* (Amazon servicio_en_la_nube Amazon Web Services (AWS\n",
            "* (Mark Zuckerberg creó Facebook\n",
            "* (Larry Page fundó Google\n",
            "* (Sergey Brin fundó Google\n",
            "* (Google es motor de búsqueda\n",
            "* (Google tipo_de_servicio motor de búsqueda\n",
            "* (Google cambió acceso a la información global\n",
            "* (Google desarrolló Android\n",
            "* (Android es sistema operativo para teléfonos inteligentes\n",
            "* (Android es sistema operativo más utilizado en teléfonos inteligentes\n",
            "Aquí tienes las relaciones extraídas del texto en formato de triples (SUJETO RELACIÓN OBJETO):\n",
            "* (Tesla tipo_de_compañía fabricante de automóviles eléctricos\n",
            "* (Tesla se_dedica_a soluciones de energía renovable\n",
            "* (SpaceX desarrolla cohetes\n",
            "* (SpaceX desarrolla satélites\n",
            "* (Apple reconocida_por productos tecnológicos innovadores\n",
            "* (Apple desarrolló iPhone\n",
            "* (Apple desarrolló iPad\n",
            "* (Apple desarrolló MacBook\n",
            "* (Apple clave_en desarrollo de la industria de los dispositivos inteligentes\n",
            "* (Apple fue_clave_en desarrollo de la industria de los dispositivos inteligentes\n",
            "* (Amazon evolucionó_a plataforma de comercio electrónico\n",
            "* (Amazon evolucionó_hacia plataforma de comercio electrónico\n",
            "* (Amazon ofrece servicios en la nube\n",
            "* (Facebook tipo_de_red red social\n",
            "* (Facebook transformó comunicación digital\n",
            "* (Facebook transformó publicidad\n",
            "* (Facebook transformó interacción en línea\n",
            "* (Android tipo_de_sistema sistema operativo\n",
            "* (Android sistema_operativo_más_utilizado teléfonos inteligentes\n",
            "* (Android uso_en teléfonos inteligentes\n",
            "* (Android sistema_operativo_mas_usado teléfonos inteligentes\n",
            "\n",
            "🔹 Respuesta generada por Gemini:\n",
            "Elon Musk fundó Tesla y SpaceX.\n",
            "\n",
            "* **Tesla:** Es una compañía fabricante de automóviles eléctricos y soluciones de energía renovable.  Su importancia radica en su contribución a la mitigación del cambio climático a través del desarrollo de vehículos eléctricos y tecnologías de energía limpia, impulsando una transición hacia una movilidad y energía más sostenibles.\n",
            "\n",
            "* **SpaceX:** Es una empresa de exploración espacial que desarrolla cohetes y satélites. Su importancia reside en su ambición de reducir los costos de acceso al espacio,  facilitando la exploración espacial y abriendo nuevas posibilidades para la investigación científica, la comunicación satelital y la colonización espacial.\n",
            "\n",
            "\n",
            "Steve Jobs fue cofundador de Apple.\n",
            "\n",
            "* **Apple:** Es una empresa reconocida por sus productos tecnológicos innovadores como el iPhone, iPad y MacBook.  Su importancia se debe a su papel clave en el desarrollo de la industria de los dispositivos inteligentes, revolucionando la forma en que interactuamos con la tecnología y creando un ecosistema de productos altamente integrado e influyente en el mercado global.  Su impacto se extiende a la creación de una cultura de diseño centrada en el usuario y a la definición de estándares en la industria tecnológica.\n",
            "\n",
            "\n",
            "🔹 Respuesta generada por Gemini sin contexto:\n",
            "No puedo responder a esta pregunta sin el contexto del grafo de conocimiento.  Necesito la información contenida en el grafo para identificar las empresas fundadas por Elon Musk y Steve Jobs, sus actividades y la importancia de las mismas.  Por favor, proporcione el grafo de conocimiento.\n",
            "\n",
            "\n",
            "🔹 Respuesta generada por Chatgpt:\n",
            "El científico que propuso un modelo atómico en **1913 fue Niels Bohr**. Bohr planteó que los electrones orbitan alrededor del núcleo en niveles de energía cuantizados, lo que permitió explicar fenómenos como las líneas espectrales del hidrógeno. Este modelo fue un gran avance respecto al de Rutherford, ya que incorporó ideas de la teoría cuántica para describir la estabilidad del átomo. De manera adicional, aunque luego fue superado por la mecánica cuántica de Schrödinger y Heisenberg, el modelo de Bohr sigue siendo muy útil en la enseñanza porque introduce de forma sencilla el concepto de niveles de energía y la transición de electrones con emisión o absorción de fotones.\n"
          ]
        }
      ],
      "source": [
        "# ================== INSTALACIÓN ==================\n",
        "!pip install neo4j google-generativeai\n",
        "\n",
        "import os\n",
        "from neo4j import GraphDatabase\n",
        "import google.generativeai as genai\n",
        "from google.colab import files\n",
        "\n",
        "# ================== CONFIGURACIÓN ==================\n",
        "# 👉 API Key de Gemini (puede usar la nuestra o crear la suya en https://aistudio.google.com/)\"\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# 👉 Configura Neo4j con tus propios datos (SOLO si falla la configuración por defecto del Colab)\n",
        "NEO4J_URI = userdata.get('urlneo')\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = userdata.get('neo4j')\n",
        "\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
        "\n",
        "# ================== SUBIR DOCUMENTO ==================\n",
        "print(\"Sube un archivo de texto con información (ej: innovadores.txt)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# ================== EXTRAER TRIPLES CON GEMINI ==================\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Extrae relaciones del siguiente texto en formato de triples:\n",
        "(SUJETO, RELACIÓN, OBJETO).\n",
        "Texto:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(\"🔹 Triples extraídos por Gemini:\")\n",
        "print(response.text)\n",
        "\n",
        "# ================== GUARDAR TRIPLES EN NEO4J ==================\n",
        "def insert_triple(tx, s, r, o):\n",
        "    query = \"\"\"\n",
        "    MERGE (a:Entidad {name: $s})\n",
        "    MERGE (b:Entidad {name: $o})\n",
        "    MERGE (a)-[rel:RELACION {tipo: $r}]->(b)\n",
        "    \"\"\"\n",
        "    tx.run(query, s=s, r=r, o=o)\n",
        "\n",
        "triples = []\n",
        "for line in response.text.split(\"\\n\"):\n",
        "    if \"(\" in line and \")\" in line:\n",
        "        line = line.strip(\"()\")\n",
        "        parts = [p.strip() for p in line.split(\",\")]\n",
        "        if len(parts) == 3:\n",
        "            triples.append(parts)\n",
        "\n",
        "with driver.session() as session:\n",
        "    for s, r, o in triples:\n",
        "        session.write_transaction(insert_triple, s, r, o)\n",
        "\n",
        "print(f\"✅ Se insertaron {len(triples)} triples en Neo4j\")\n",
        "\n",
        "# ================== CONSULTA AL GRAFO ==================\n",
        "def query_graph(query):\n",
        "    with driver.session() as session:\n",
        "        result = session.run(query)\n",
        "        return [dict(r) for r in result]\n",
        "\n",
        "# AQUI PUEDEN CAMBIAR LAS QUERY POR LOS EJEMPLOS DE ARRIBA ============================== ⏰⏰⏰ =============================\n",
        "cypher_query = \"\"\"\n",
        "MATCH (p:Entidad)-[r:RELACION]->(c:Entidad)\n",
        "RETURN p.name AS persona, r.tipo AS relacion, c.name AS compania\n",
        "\"\"\"\n",
        "\n",
        "results = query_graph(cypher_query)\n",
        "\n",
        "print(\"\\n🔹 Resultados de la consulta Cypher:\")\n",
        "for r in results:\n",
        "    print(f\"{r['persona']} {r['relacion']} {r['compania']}\")\n",
        "\n",
        "# ================== GEMINI PARA RESPUESTA FINAL ==================\n",
        "context = \"\\n\".join([f\"{r['persona']} {r['relacion']} {r['compania']}\" for r in results])\n",
        "\n",
        "# AQUI PUEDEN CAMBIAR LAS PREGUNTAS POR LOS EJEMPLOS DE ARRIBA ============================== ⏰⏰⏰ =============================\n",
        "\n",
        "final_prompt = f\"\"\"\n",
        "Basándote en el siguiente contexto de un grafo de conocimiento, responde la pregunta y proporciona contexto:\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pregunta:  ¿Cuáles son las empresas fundadas por Elon Musk y por Steve Jobs, a qué se dedica cada una y por qué es importante lo que hacen?\n",
        "\"\"\"\n",
        "\n",
        "final_prompt_no_context = f\"\"\"\n",
        "Basándote en el siguiente contexto de un grafo de conocimiento, responde la pregunta y proporciona contexto:\n",
        "\n",
        "Pregunta:  ¿Cuáles son las empresas fundadas por Elon Musk y por Steve Jobs, a qué se dedica cada una y por qué es importante lo que hacen?\n",
        "\"\"\"\n",
        "\n",
        "response_final = model.generate_content(final_prompt)\n",
        "\n",
        "response_no_context = model.generate_content(final_prompt_no_context)\n",
        "\n",
        "respuesta_chat = \"\"\"Elon Musk fundó Tesla y SpaceX, además de participar en la creación de PayPal.\n",
        "\n",
        "* **Tesla:** Es una compañía dedicada a la fabricación de automóviles eléctricos y soluciones de energía renovable. Su importancia radica en su contribución a la lucha contra el cambio climático mediante la promoción de vehículos eléctricos y energías limpias, además de impulsar la innovación en el sector automotriz.\n",
        "\n",
        "* **SpaceX:** Es una empresa de exploración espacial que desarrolla y lanza cohetes y satélites. Su importancia reside en su objetivo de reducir los costos del acceso al espacio, facilitar la colonización de Marte y promover la innovación tecnológica en el sector aeroespacial. Contribuye a la exploración espacial y al desarrollo de nuevas tecnologías.\n",
        "\n",
        "* **PayPal:** Es un sistema de pagos en línea que transformó la manera en que se realizan transacciones digitales. Su importancia se encuentra en haber ofrecido una forma segura, rápida y global de realizar pagos por internet, siendo pionera en la economía digital.\n",
        "\n",
        "Steve Jobs fue cofundador de Apple.\n",
        "\n",
        "* **Apple:** Es una empresa reconocida por sus productos tecnológicos innovadores como el iPhone, iPad y MacBook. Su importancia se debe a su influencia en la industria de los dispositivos inteligentes, al establecer estándares de diseño y usabilidad, y revolucionar la manera en que las personas interactúan con la tecnología. Ha sido clave en el desarrollo de esta industria, popularizando conceptos como la interfaz gráfica intuitiva y la integración de software y hardware.\"\"\"\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada por Gemini:\")\n",
        "print(response_final.text)\n",
        "\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada por Gemini sin contexto:\")\n",
        "print(response_no_context.text)\n",
        "\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada por Chatgpt:\")\n",
        "print(response_chat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Métricas de evaluación"
      ],
      "metadata": {
        "id": "lbWjtnEpQW-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 8. COMPARACIÓN E INTERPRETACIÓN DE RESULTADOS =========\n",
        "\n",
        "print(\"\\n=== Comparación e Interpretación de las Métricas ===\")\n",
        "\n",
        "print(\"\\nComparando las respuestas generadas con la referencia (ChatGPT):\")\n",
        "\n",
        "bue_score_context, rouge_score_context = evaluate_response(response, respuesta_chat)\n",
        "bue_score_no_context, rouge_score_no_context = evaluate_response_no_context(response_no_context, respuesta_chat)\n",
        "\n",
        "# Compare BLEU scores\n",
        "print(\"\\nResultados BLEU:\")\n",
        "print(f\"- Gemini con contexto (BLEU): {bleu_score_context['bleu']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (BLEU): {bleu_score_no_context['bleu']:.4f}\")\n",
        "\n",
        "if bleu_score_context['bleu'] > bleu_score_no_context['bleu']:\n",
        "    print(\"  -> Según el BLEU score general, la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif bleu_score_context['bleu'] < bleu_score_no_context['bleu']:\n",
        "     print(\"  -> Según el BLEU score general, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los BLEU scores generales son similares.\")\n",
        "\n",
        "print(\"\\nResultados ROUGE:\")\n",
        "print(f\"- Gemini con contexto (ROUGE-1): {rouge_score_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-1): {rouge_score_no_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini con contexto (ROUGE-L): {rouge_score_context['rougeL']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-L): {rouge_score_no_context['rougeL']:.4f}\")\n",
        "\n",
        "\n",
        "if rouge_score_context['rouge1'] > rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> Según ROUGE-1 (superposición de palabras individuales), la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif rouge_score_context['rouge1'] < rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> Según ROUGE-1, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los ROUGE-1 scores son similares.\")\n",
        "\n",
        "if rouge_score_context['rougeL'] > rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> Según ROUGE-L (subsecuencia más larga, sensible al orden), la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif rouge_score_context['rougeL'] < rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> Según ROUGE-L, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "     print(\"  -> Los ROUGE-L scores son similares.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eXr6mx3OJNy",
        "outputId": "cafd2cd1-0c4b-4af6-e3bb-6c5d2a11ea52"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Comparación e Interpretación de las Métricas ===\n",
            "\n",
            "Comparando las respuestas generadas con la referencia (ChatGPT):\n",
            "\n",
            "🔹 BLEU score (Gemini with context): 0.0000\n",
            "🔹 BLEU precision scores (Gemini with context):\n",
            "- Precision@1: 0.0960\n",
            "- Precision@2: 0.0067\n",
            "- Precision@3: 0.0000\n",
            "- Precision@4: 0.0000\n",
            "\n",
            "🔹 ROUGE score (Gemini with context):\n",
            "- rouge1: 0.2222\n",
            "- rouge2: 0.0260\n",
            "- rougeL: 0.1292\n",
            "- rougeLsum: 0.1499\n",
            "\n",
            "🔹 BLEU score (Gemini without context): 0.0000\n",
            "\n",
            "🔹 ROUGE score (Gemini without context):\n",
            "- rouge1: 0.1965\n",
            "- rouge2: 0.0117\n",
            "- rougeL: 0.1272\n",
            "- rougeLsum: 0.1272\n",
            "\n",
            "Resultados BLEU:\n",
            "- Gemini con contexto (BLEU): 0.0904\n",
            "- Gemini sin contexto (BLEU): 0.0896\n",
            "  -> Según el BLEU score general, la respuesta de Gemini con contexto es más similar a la referencia.\n",
            "\n",
            "Resultados ROUGE:\n",
            "- Gemini con contexto (ROUGE-1): 0.2222\n",
            "- Gemini sin contexto (ROUGE-1): 0.1965\n",
            "- Gemini con contexto (ROUGE-L): 0.1292\n",
            "- Gemini sin contexto (ROUGE-L): 0.1272\n",
            "  -> Según ROUGE-1 (superposición de palabras individuales), la respuesta de Gemini con contexto es más similar a la referencia.\n",
            "  -> Según ROUGE-L (subsecuencia más larga, sensible al orden), la respuesta de Gemini con contexto es más similar a la referencia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df4UpK7chNL3"
      },
      "source": [
        "# 3. **FusionRAG (BM25 + Embeddings)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9VZtHlqhMXn"
      },
      "source": [
        "En este ejemplo se combina lo mejor de dos enfoques de recuperación de información:\n",
        "\n",
        "- BM25 (keyword-based): Recupera pasajes basándose en la coincidencia de palabras clave.\n",
        "\n",
        "- Vector Search (embeddings con ChromaDB): Recupera fragmentos usando similitud semántica.\n",
        "\n",
        "Ambos resultados se fusionan para obtener un contexto más robusto y completo, que luego se pasa al modelo Gemini para generar una respuesta.\n",
        "\n",
        "👉 Deben subir un archivo de texto (ej: cuantica.txt, historia_colombia.txt, innovadores.txt o historia_internet.txt) y luego probar con diferentes preguntas modificando el campo query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF1FWJa_0GIg"
      },
      "source": [
        "## **Preparación del entorno:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9avBZ7T00GlQ"
      },
      "source": [
        "Si ya configuraste los entornos de los ejemplos anteriores, no necesitas hacer nada adicional para este bloque. 🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "s7Q2HHrgeQSM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e50a3040-779e-40ff-b274-341a19aa8d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.182.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "📂 Sube un archivo de texto con información (ej: cuantica.txt, historia_colombia.txt, etc.)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e5f10283-8939-4c7c-b45c-601f005b4905\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e5f10283-8939-4c7c-b45c-601f005b4905\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cuantica.txt to cuantica (3).txt\n",
            "\n",
            "🔹 Respuesta generada con FusionRAG:\n",
            "Niels Bohr propuso un modelo atómico en 1913.  El texto explícitamente menciona que en ese año, Bohr propuso su modelo atómico donde los electrones orbitaban en niveles de energía cuantizados alrededor del núcleo.  La información sobre la independencia de Colombia es irrelevante para responder a esta pregunta específica.\n",
            "\n",
            "\n",
            "🔹 Respuesta generada por Gemini sin contexto:\n",
            "El científico que propuso un modelo atómico en 1913 fue **Niels Bohr**.\n",
            "\n",
            "La explicación reside en que el modelo atómico de Bohr, publicado en 1913,  fue una mejora significativa al modelo de Rutherford.  Si bien el modelo de Rutherford describió correctamente la existencia de un núcleo atómico positivo con electrones orbitándolo, no explicaba la estabilidad del átomo.  El modelo de Bohr incorporó la teoría cuántica de Planck, postulando que los electrones orbitan el núcleo en órbitas específicas con niveles de energía definidos, y que los electrones solo pueden saltar entre estas órbitas absorbiendo o emitiendo fotones de energía específica.  Esto solucionaba el problema de la inestabilidad del modelo de Rutherford, ya que impedía que los electrones cayeran en el núcleo.  Por lo tanto, el modelo de Bohr de 1913 es un hito en la historia de la física atómica.\n",
            "\n",
            "\n",
            "🔹 Respuesta generada por Chatgpt:\n",
            "El científico que propuso un modelo atómico en 1913 fue Niels Bohr\n",
            "\n",
            "Bohr planteó que los electrones no podían ocupar cualquier órbita alrededor del núcleo, sino que se encontraban en niveles de energía cuantizados. Esto significaba que los electrones solo podían moverse entre niveles discretos, emitiendo o absorbiendo energía en forma de cuantos (fotones). Su modelo fue una mejora respecto al de Rutherford, ya que explicaba fenómenos como el espectro del hidrógeno, donde las líneas de emisión correspondían a transiciones electrónicas entre estos niveles.\n",
            "\n",
            "Este aporte fue crucial porque introdujo el concepto de cuantización al modelo atómico, conectando las ideas de Planck y Einstein con la estructura de la materia, y sentando las bases de la mecánica cuántica moderna.\n"
          ]
        }
      ],
      "source": [
        "# ================= DEMO FUSION RAG ==================\n",
        "!pip install rank_bm25 chromadb sentence-transformers google-generativeai\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# ================= SUBIR DOCUMENTO ==================\n",
        "print(\"📂 Sube un archivo de texto con información (ej: cuantica.txt, historia_colombia.txt, etc.)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# ================= CHUNKING ==================\n",
        "def chunk_text(text, chunk_size=80, overlap=20):\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size - overlap)]\n",
        "\n",
        "docs = chunk_text(text)\n",
        "\n",
        "# ========= Vector Store (embeddings con ChromaDB)\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "client = chromadb.Client()\n",
        "collection = client.get_or_create_collection(\"fusion_chunks\")\n",
        "embeddings = embedder.encode(docs).tolist()\n",
        "for i, d in enumerate(docs):\n",
        "    collection.add(documents=[d], embeddings=[embeddings[i]], ids=[str(i)])\n",
        "\n",
        "# ========= BM25 retriever\n",
        "tokenized_corpus = [d.split(\" \") for d in docs]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# ========= Fusion Retrieval\n",
        "query = \"¿Qué científico propuso un modelo atómico en 1913?\"\n",
        "q_embed = embedder.encode([query]).tolist()\n",
        "results_vector = collection.query(query_embeddings=q_embed, n_results=3)\n",
        "results_bm25 = bm25.get_top_n(query.split(\" \"), docs, n=3)\n",
        "\n",
        "# Fusión (simple: concatenación + eliminación de duplicados)\n",
        "fusion_results = list(set(results_vector['documents'][0] + results_bm25))\n",
        "retrieved_context = \" \".join(fusion_results)\n",
        "\n",
        "# ================= GEMINI PARA RESPUESTA FINAL ==================\n",
        "response = model.generate_content(\n",
        "    f\"Basándote en el siguiente contexto (resultado de fusión de múltiples recuperadores), responde la pregunta y añade explicación:\\n\\n{retrieved_context}\\n\\nPregunta: {query}\"\n",
        ")\n",
        "\n",
        "\n",
        "response_no_context = model.generate_content(\n",
        "    f\"Basándote en el siguiente contexto (resultado de fusión de múltiples recuperadores), responde la pregunta y añade explicación:\\n\\nPregunta: {query}\"\n",
        ")\n",
        "\n",
        "response_chat = \"\"\"El científico que propuso un modelo atómico en 1913 fue Niels Bohr\n",
        "\n",
        "Bohr planteó que los electrones no podían ocupar cualquier órbita alrededor del núcleo, sino que se encontraban en niveles de energía cuantizados. Esto significaba que los electrones solo podían moverse entre niveles discretos, emitiendo o absorbiendo energía en forma de cuantos (fotones). Su modelo fue una mejora respecto al de Rutherford, ya que explicaba fenómenos como el espectro del hidrógeno, donde las líneas de emisión correspondían a transiciones electrónicas entre estos niveles.\n",
        "\n",
        "Este aporte fue crucial porque introdujo el concepto de cuantización al modelo atómico, conectando las ideas de Planck y Einstein con la estructura de la materia, y sentando las bases de la mecánica cuántica moderna.\"\"\"\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada con FusionRAG:\")\n",
        "print(response.text)\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada por Gemini sin contexto:\")\n",
        "print(response_no_context.text)\n",
        "\n",
        "\n",
        "print(\"\\n🔹 Respuesta generada por Chatgpt:\")\n",
        "print(response_chat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Métricas de evaluación"
      ],
      "metadata": {
        "id": "Gn0flFdbSin2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 8. COMPARACIÓN E INTERPRETACIÓN DE RESULTADOS =========\n",
        "\n",
        "print(\"\\n=== Comparación e Interpretación de las Métricas ===\")\n",
        "\n",
        "print(\"\\nComparando las respuestas generadas con la referencia (ChatGPT):\")\n",
        "\n",
        "bue_score_context, rouge_score_context = evaluate_response(response, response_chat)\n",
        "bue_score_no_context, rouge_score_no_context = evaluate_response_no_context(response_no_context, response_chat)\n",
        "\n",
        "# Compare BLEU scores\n",
        "print(\"\\nResultados BLEU:\")\n",
        "print(f\"- Gemini con contexto (BLEU): {bleu_score_context['bleu']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (BLEU): {bleu_score_no_context['bleu']:.4f}\")\n",
        "\n",
        "if bleu_score_context['bleu'] > bleu_score_no_context['bleu']:\n",
        "    print(\"  -> Según el BLEU score general, la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif bleu_score_context['bleu'] < bleu_score_no_context['bleu']:\n",
        "     print(\"  -> Según el BLEU score general, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los BLEU scores generales son similares.\")\n",
        "\n",
        "print(\"\\nResultados ROUGE:\")\n",
        "print(f\"- Gemini con contexto (ROUGE-1): {rouge_score_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-1): {rouge_score_no_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini con contexto (ROUGE-L): {rouge_score_context['rougeL']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-L): {rouge_score_no_context['rougeL']:.4f}\")\n",
        "\n",
        "\n",
        "if rouge_score_context['rouge1'] > rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> Según ROUGE-1 (superposición de palabras individuales), la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif rouge_score_context['rouge1'] < rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> Según ROUGE-1, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los ROUGE-1 scores son similares.\")\n",
        "\n",
        "if rouge_score_context['rougeL'] > rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> Según ROUGE-L (subsecuencia más larga, sensible al orden), la respuesta de Gemini con contexto es más similar a la referencia.\")\n",
        "elif rouge_score_context['rougeL'] < rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> Según ROUGE-L, la respuesta de Gemini sin contexto es más similar a la referencia.\")\n",
        "else:\n",
        "     print(\"  -> Los ROUGE-L scores son similares.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwRd99o-RHQz",
        "outputId": "34ec9378-c607-4ee2-f619-44f225223b1a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Comparación e Interpretación de las Métricas ===\n",
            "\n",
            "Comparando las respuestas generadas con la referencia (ChatGPT):\n",
            "\n",
            "🔹 BLEU score (Gemini with context): 0.0502\n",
            "🔹 BLEU precision scores (Gemini with context):\n",
            "- Precision@1: 0.6154\n",
            "- Precision@2: 0.2745\n",
            "- Precision@3: 0.1600\n",
            "- Precision@4: 0.1020\n",
            "\n",
            "🔹 ROUGE score (Gemini with context):\n",
            "- rouge1: 0.3854\n",
            "- rouge2: 0.2000\n",
            "- rougeL: 0.2188\n",
            "- rougeLsum: 0.2812\n",
            "\n",
            "🔹 BLEU score (Gemini without context): 0.1580\n",
            "\n",
            "🔹 ROUGE score (Gemini without context):\n",
            "- rouge1: 0.5051\n",
            "- rouge2: 0.2405\n",
            "- rougeL: 0.3276\n",
            "- rougeLsum: 0.3823\n",
            "\n",
            "Resultados BLEU:\n",
            "- Gemini con contexto (BLEU): 0.0904\n",
            "- Gemini sin contexto (BLEU): 0.0896\n",
            "  -> Según el BLEU score general, la respuesta de Gemini con contexto es más similar a la referencia.\n",
            "\n",
            "Resultados ROUGE:\n",
            "- Gemini con contexto (ROUGE-1): 0.3854\n",
            "- Gemini sin contexto (ROUGE-1): 0.5051\n",
            "- Gemini con contexto (ROUGE-L): 0.2188\n",
            "- Gemini sin contexto (ROUGE-L): 0.3276\n",
            "  -> Según ROUGE-1, la respuesta de Gemini sin contexto es más similar a la referencia.\n",
            "  -> Según ROUGE-L, la respuesta de Gemini sin contexto es más similar a la referencia.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "jd0d13ZvGXGW",
        "iyQtSj8YhcW3"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}