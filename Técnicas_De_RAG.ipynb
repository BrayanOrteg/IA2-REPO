{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0hVNAozgzJm"
      },
      "source": [
        "# **1. Demo BÃ¡sica de Retrieval-Augmented Generation (BasicRAG) con Gemini:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeijQZB2qbFn"
      },
      "source": [
        "## Â¿CÃ³mo funciona?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8VqoaXmgsgX"
      },
      "source": [
        "En este ejemplo veremos cÃ³mo funciona un sistema bÃ¡sico de RAG (Retrieval-Augmented Generation).\n",
        "La idea principal es:\n",
        "\n",
        "1. Subir un documento de texto (ejemplo: un archivo con informaciÃ³n de fÃ­sica cuÃ¡ntica o historia).\n",
        "\n",
        "2. Dividir el documento en fragmentos pequeÃ±os (chunks).\n",
        "\n",
        "3. Convertir esos fragmentos en embeddings (vectores numÃ©ricos que representan el significado del texto).\n",
        "\n",
        "4. Guardar los embeddings en una base de datos vectorial (ChromaDB).\n",
        "\n",
        "5. Hacer una pregunta en lenguaje natural â†’ el sistema busca los fragmentos mÃ¡s relevantes.\n",
        "\n",
        "6. Gemini responde usando esos fragmentos como contexto, para dar una respuesta mÃ¡s precisa y confiable.\n",
        "\n",
        "Esto es lo que hace especial a RAG: el modelo no depende solo de su memoria entrenada, sino que consulta informaciÃ³n externa que nosotros le damos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7VmJZQKqtlO"
      },
      "source": [
        "## **PreparaciÃ³n del entorno:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vc0XyXyqxZu"
      },
      "source": [
        "**Antes de ejecutar el cÃ³digo:**\n",
        "\n",
        "1. **Obtener tu API Key de Gemini:**\n",
        "\n",
        "- Entra a ğŸ‘‰ Google AI Studio: https://aistudio.google.com/.\n",
        "\n",
        "- Crea una clave desde la secciÃ³n API Keys.\n",
        "\n",
        "- Copia tu API Key y reemplaza en la lÃ­nea: **os.environ[\"GEMINI_API_KEY\"] = \"TU_API_KEY_AQUI\"**\n",
        "\n",
        "\n",
        "**Este paso solo es necesario si la que estÃ¡ puesta falla, o si cada estudiante quiere usar su propia clave.**\n",
        "\n",
        "2. **Archivos de prueba disponibles en Drive (Debajo se indican los documentos utilizados en la demo en calse): https://drive.google.com/drive/folders/1uF7-oSMpzSdID2ltQf9NsU5Snf16fHfx?usp=sharing**\n",
        "\n",
        "- cuantica.txt â†’ introducciÃ³n a la fÃ­sica cuÃ¡ntica. **(Usado en al demo en clase)**.\n",
        "\n",
        "- innovadores.txt â†’ introducciÃ³n a la fÃ­sica cuÃ¡ntica. **(Usado en al demo en clase)**.\n",
        "\n",
        "- historia_Colombia.txt â†’ texto sobre historia de Colombia.\n",
        "\n",
        "- historia_internet.txt â†’ documento con explicaciÃ³n bÃ¡sica de Einstein.\n",
        "\n",
        "ğŸ‘‰ **Suban uno de estos archivos (o el suyo propio) cuando el cÃ³digo lo pida.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate==0.4.5\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "J9q_nPxVGRxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6969c6d7-e78a-4a72-fd35-ea6fe42f16f3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate==0.4.5 in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.5) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.5) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.5) (1.17.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Clo-IDEYWys-",
        "outputId": "53972817-4415-41b7-edc6-9c93b38a2327"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.182.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.37.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading chromadb-1.1.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.37.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=ba5c6bdeffaa2b0dd2b99ea79c66a4da5b72a4e01beab8091c657f2d640fd4b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.1.0 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-common-1.37.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 opentelemetry-proto-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# ================= DEMO RAG CON GEMINI ==================\n",
        "!pip install chromadb sentence-transformers google-generativeai\n",
        "\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 1. CONFIGURACIÃ“N DE GEMINI =========\n",
        "# ğŸ‘‰ Paso previo: obtener API Key en https://aistudio.google.com/\n",
        "#  Cambia tu API Key SOLO si la actual no funciona.\n",
        "from google.colab import userdata\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('gemini')\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
      ],
      "metadata": {
        "id": "lz8oh3LUZXBK"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 2. SUBIR ARCHIVO =========\n",
        "print(\"Sube un archivo de texto con informaciÃ³n (ej: cuantica.txt)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "FpgCoeChZZVS",
        "outputId": "9c6238d4-7c12-4226-d8f9-da384420701a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sube un archivo de texto con informaciÃ³n (ej: cuantica.txt)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-88a88125-7569-4c55-b54d-a5b1692dce70\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-88a88125-7569-4c55-b54d-a5b1692dce70\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1834540293.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ========= 2. SUBIR ARCHIVO =========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sube un archivo de texto con informaciÃ³n (ej: cuantica.txt)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 3. FUNCIÃ“N DE CHUNKING =========\n",
        "def chunk_text(text, chunk_size=80, overlap=20):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    for i in range(0, len(words), chunk_size - overlap):\n",
        "        chunk = \" \".join(words[i:i+chunk_size])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "docs = chunk_text(text, chunk_size=80, overlap=20)\n",
        "\n",
        "print(\"Ejemplo de 3 chunks creados:\")\n",
        "for c in docs[:3]:\n",
        "    print(\"-\", c, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_XL00sOZhnE",
        "outputId": "221380c2-49c0-4a5c-b9eb-3c84fdd3eed6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de 3 chunks creados:\n",
            "- Elon Musk fundÃ³ Tesla, una compaÃ±Ã­a dedicada a la fabricaciÃ³n de automÃ³viles elÃ©ctricos y soluciones de energÃ­a renovable. TambiÃ©n fundÃ³ SpaceX, una empresa de exploraciÃ³n espacial que desarrolla cohetes y satÃ©lites. AdemÃ¡s, participÃ³ en la creaciÃ³n de PayPal, un sistema de pagos en lÃ­nea que revolucionÃ³ las transacciones digitales. Steve Jobs fue cofundador de Apple, empresa reconocida por sus productos tecnolÃ³gicos innovadores como el iPhone, iPad y MacBook. Apple ha sido clave en el desarrollo de la industria de los \n",
            "\n",
            "- tecnolÃ³gicos innovadores como el iPhone, iPad y MacBook. Apple ha sido clave en el desarrollo de la industria de los dispositivos inteligentes. Jeff Bezos fundÃ³ Amazon, inicialmente como una librerÃ­a en lÃ­nea, que evolucionÃ³ hacia una de las mayores plataformas de comercio electrÃ³nico y servicios en la nube a travÃ©s de Amazon Web Services (AWS). Mark Zuckerberg creÃ³ Facebook, una red social que transformÃ³ la comunicaciÃ³n digital, la publicidad y la interacciÃ³n en lÃ­nea. Larry Page y Sergey Brin fundaron \n",
            "\n",
            "- red social que transformÃ³ la comunicaciÃ³n digital, la publicidad y la interacciÃ³n en lÃ­nea. Larry Page y Sergey Brin fundaron Google, un motor de bÃºsqueda que cambiÃ³ el acceso a la informaciÃ³n global. Google tambiÃ©n desarrollÃ³ Android, el sistema operativo mÃ¡s utilizado en telÃ©fonos inteligentes. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 4. CREAR EMBEDDINGS Y BASE VECTORIAL =========\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "client = chromadb.Client()\n",
        "collection = client.get_or_create_collection(\"physics_chunks\")\n",
        "\n",
        "embeddings = embedder.encode(docs).tolist()\n",
        "for i, d in enumerate(docs):\n",
        "    collection.add(documents=[d], embeddings=[embeddings[i]], ids=[str(i)])\n",
        "\n"
      ],
      "metadata": {
        "id": "RcIzv2tYZbtk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 5. CONSULTA Y RETRIEVAL =========\n",
        "# ğŸ‘‰ AquÃ­ puedes cambiar la pregunta y experimentar ========================================\n",
        "# Ejemplos para probar:\n",
        "# query = \"Â¿QuÃ© explica la teorÃ­a de la relatividad?\"\n",
        "# query = \"Â¿CuÃ¡l fue un hecho clave en la independencia de Colombia?\"\n",
        "query = \"Â¿QuÃ© cientÃ­fico propuso un modelo atÃ³mico en 1913?\"\n",
        "q_embed = embedder.encode([query]).tolist()\n",
        "results = collection.query(query_embeddings=q_embed, n_results=3)\n",
        "retrieved_context = \" \".join(results['documents'][0])\n",
        "\n",
        "print(\"\\nğŸ”¹ Chunks relevantes recuperados:\")\n",
        "for doc in results['documents'][0]:\n",
        "    print(\"-\", doc)\n",
        "\n",
        "print(\"\\nğŸ”¹ Contexto recuperado:\")\n",
        "print(retrieved_context)"
      ],
      "metadata": {
        "id": "6FwLXClZZdOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f4c3a5-fa3b-44bc-c22e-1b4389181c35"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¹ Chunks relevantes recuperados:\n",
            "- Max Planck introdujo en 1900 la idea de que la energÃ­a no se emite de manera continua, sino en cuantos discretos. Este fue el inicio de la teorÃ­a cuÃ¡ntica. Albert Einstein en 1905 explicÃ³ el efecto fotoelÃ©ctrico utilizando el concepto de cuantos de luz, lo que posteriormente llamÃ³ fotones. Niels Bohr en 1913 propuso su modelo atÃ³mico, donde los electrones orbitaban en niveles de energÃ­a cuantizados alrededor del nÃºcleo. Werner Heisenberg enunciÃ³ en 1927 el principio de incertidumbre, que indica\n",
            "- orbitaban en niveles de energÃ­a cuantizados alrededor del nÃºcleo. Werner Heisenberg enunciÃ³ en 1927 el principio de incertidumbre, que indica que no es posible conocer con precisiÃ³n la posiciÃ³n y el momento de una partÃ­cula al mismo tiempo. Erwin SchrÃ¶dinger desarrollÃ³ la ecuaciÃ³n de onda en 1926, fundamental para describir el comportamiento cuÃ¡ntico de las partÃ­culas. Richard Feynman contribuyÃ³ a la electrodinÃ¡mica cuÃ¡ntica y popularizÃ³ el uso de diagramas que llevan su nombre.\n",
            "- la electrodinÃ¡mica cuÃ¡ntica y popularizÃ³ el uso de diagramas que llevan su nombre.\n",
            "\n",
            "ğŸ”¹ Contexto recuperado:\n",
            "Max Planck introdujo en 1900 la idea de que la energÃ­a no se emite de manera continua, sino en cuantos discretos. Este fue el inicio de la teorÃ­a cuÃ¡ntica. Albert Einstein en 1905 explicÃ³ el efecto fotoelÃ©ctrico utilizando el concepto de cuantos de luz, lo que posteriormente llamÃ³ fotones. Niels Bohr en 1913 propuso su modelo atÃ³mico, donde los electrones orbitaban en niveles de energÃ­a cuantizados alrededor del nÃºcleo. Werner Heisenberg enunciÃ³ en 1927 el principio de incertidumbre, que indica orbitaban en niveles de energÃ­a cuantizados alrededor del nÃºcleo. Werner Heisenberg enunciÃ³ en 1927 el principio de incertidumbre, que indica que no es posible conocer con precisiÃ³n la posiciÃ³n y el momento de una partÃ­cula al mismo tiempo. Erwin SchrÃ¶dinger desarrollÃ³ la ecuaciÃ³n de onda en 1926, fundamental para describir el comportamiento cuÃ¡ntico de las partÃ­culas. Richard Feynman contribuyÃ³ a la electrodinÃ¡mica cuÃ¡ntica y popularizÃ³ el uso de diagramas que llevan su nombre. la electrodinÃ¡mica cuÃ¡ntica y popularizÃ³ el uso de diagramas que llevan su nombre.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 6. GEMINI PARA RESPONDER CON CONTEXTO =========\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
        "\n",
        "response = model.generate_content(\n",
        "    f\"UBasÃ¡ndote en el siguiente contexto, responde la pregunta y aÃ±ade una breve explicaciÃ³n adicional desde tu conocimiento si es relevante:.\\n\\nContexto:\\n{retrieved_context}\\n\\nPregunta: {query}\"\n",
        ")\n",
        "\n",
        "response_no_context = model.generate_content(\n",
        "    f\"UBasÃ¡ndote en el siguiente contexto, responde la pregunta y aÃ±ade una breve explicaciÃ³n adicional desde tu conocimiento si es relevante:.\\n\\nPregunta: {query}\"\n",
        ")\n",
        "\n",
        "response_chat = \"El cientÃ­fico que propuso un modelo atÃ³mico en **1913 fue Niels Bohr**. Bohr planteÃ³ que los electrones orbitan alrededor del nÃºcleo en niveles de energÃ­a cuantizados, lo que permitiÃ³ explicar fenÃ³menos como las lÃ­neas espectrales del hidrÃ³geno. Este modelo fue un gran avance respecto al de Rutherford, ya que incorporÃ³ ideas de la teorÃ­a cuÃ¡ntica para describir la estabilidad del Ã¡tomo. De manera adicional, aunque luego fue superado por la mecÃ¡nica cuÃ¡ntica de SchrÃ¶dinger y Heisenberg, el modelo de Bohr sigue siendo muy Ãºtil en la enseÃ±anza porque introduce de forma sencilla el concepto de niveles de energÃ­a y la transiciÃ³n de electrones con emisiÃ³n o absorciÃ³n de fotones.\"\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada por Gemini:\")\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada por Gemini sin contexto:\")\n",
        "print(response_no_context.text)\n",
        "\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada por Chatgpt:\")\n",
        "print(response_chat)"
      ],
      "metadata": {
        "id": "JEhZG15cZfDU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "fdcb0172-8cc2-4256-b4d5-696da1cd4d0e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”¹ Respuesta generada por Gemini:\n",
            "Niels Bohr propuso un modelo atÃ³mico en 1913.  Este modelo incorporaba la idea de cuantizaciÃ³n de la energÃ­a, postulada previamente por Planck, para explicar la estabilidad del Ã¡tomo y las lÃ­neas espectrales del hidrÃ³geno.  A diferencia de los modelos atÃ³micos anteriores, el de Bohr planteaba que los electrones orbitaban el nÃºcleo en niveles de energÃ­a discretos y definidos, y que la emisiÃ³n o absorciÃ³n de energÃ­a ocurrÃ­a cuando un electrÃ³n saltaba entre estos niveles.  Si bien este modelo tenÃ­a limitaciones y fue posteriormente superado por la mecÃ¡nica cuÃ¡ntica, fue un paso crucial en la comprensiÃ³n de la estructura atÃ³mica.\n",
            "\n",
            "\n",
            "ğŸ”¹ Respuesta generada por Gemini sin contexto:\n",
            "Niels Bohr propuso un modelo atÃ³mico en 1913.\n",
            "\n",
            "**ExplicaciÃ³n adicional:** El modelo atÃ³mico de Bohr mejorÃ³ significativamente el modelo de Rutherford al incorporar la teorÃ­a cuÃ¡ntica de Planck.  A diferencia del modelo de Rutherford, que dejaba sin explicar la estabilidad de los Ã¡tomos (los electrones deberÃ­an caer en espiral hacia el nÃºcleo), Bohr postulÃ³ que los electrones orbitan el nÃºcleo en niveles de energÃ­a especÃ­ficos y cuantizados.  Solo pueden existir en estas Ã³rbitas definidas y  absorben o emiten energÃ­a al saltar entre ellas. Este modelo, aunque posteriormente fue reemplazado por modelos mÃ¡s complejos y precisos (como la mecÃ¡nica cuÃ¡ntica), fue un paso crucial en la comprensiÃ³n de la estructura atÃ³mica y sentÃ³ las bases para futuros desarrollos en la fÃ­sica atÃ³mica y la quÃ­mica cuÃ¡ntica.\n",
            "\n",
            "\n",
            "ğŸ”¹ Respuesta generada por Chatgpt:\n",
            "El cientÃ­fico que propuso un modelo atÃ³mico en **1913 fue Niels Bohr**. Bohr planteÃ³ que los electrones orbitan alrededor del nÃºcleo en niveles de energÃ­a cuantizados, lo que permitiÃ³ explicar fenÃ³menos como las lÃ­neas espectrales del hidrÃ³geno. Este modelo fue un gran avance respecto al de Rutherford, ya que incorporÃ³ ideas de la teorÃ­a cuÃ¡ntica para describir la estabilidad del Ã¡tomo. De manera adicional, aunque luego fue superado por la mecÃ¡nica cuÃ¡ntica de SchrÃ¶dinger y Heisenberg, el modelo de Bohr sigue siendo muy Ãºtil en la enseÃ±anza porque introduce de forma sencilla el concepto de niveles de energÃ­a y la transiciÃ³n de electrones con emisiÃ³n o absorciÃ³n de fotones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MÃ©tricas de evaluaciÃ³n"
      ],
      "metadata": {
        "id": "jd0d13ZvGXGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "\n",
        "def evaluate_response(response, reference_response):\n",
        "  # Generated response from Gemini with context\n",
        "  generated_response_context = response.text\n",
        "  # Reference response from chatgpt\n",
        "  reference_response = response_chat\n",
        "\n",
        "  # Calculate BLEU score for context\n",
        "  bleu = load(\"bleu\")\n",
        "  bleu_score_context = bleu.compute(predictions=[generated_response_context], references=[reference_response])\n",
        "  print(f\"\\nğŸ”¹ BLEU score (Gemini with context): {bleu_score_context['bleu']:.4f}\")\n",
        "  print(\"ğŸ”¹ BLEU precision scores (Gemini with context):\")\n",
        "  for i, precision in enumerate(bleu_score_context['precisions']):\n",
        "      print(f\"- Precision@{i+1}: {precision:.4f}\")\n",
        "\n",
        "  # Calculate ROUGE score for context\n",
        "  rouge = load(\"rouge\")\n",
        "  rouge_score_context = rouge.compute(predictions=[generated_response_context], references=[reference_response])\n",
        "  print(\"\\nğŸ”¹ ROUGE score (Gemini with context):\")\n",
        "  for key, value in rouge_score_context.items():\n",
        "      print(f\"- {key}: {value:.4f}\")\n",
        "\n",
        "  return bleu_score_context, rouge_score_context"
      ],
      "metadata": {
        "id": "Re55YnZP6SY_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_response_no_context(response, reference_response):\n",
        "  # Generated response from Gemini with no context\n",
        "  generated_response_no_context = response_no_context.text\n",
        "  # Reference response from chatgpt\n",
        "  reference_response = response_chat\n",
        "\n",
        "  # Calculate BLEU score for no context\n",
        "  bleu = load(\"bleu\")\n",
        "  bleu_score_no_context = bleu.compute(predictions=[generated_response_no_context], references=[reference_response])\n",
        "  print(f\"\\nğŸ”¹ BLEU score (Gemini without context): {bleu_score_no_context['bleu']:.4f}\")\n",
        "\n",
        "  # Calculate ROUGE score for no context\n",
        "  rouge = load(\"rouge\")\n",
        "  rouge_score_no_context = rouge.compute(predictions=[generated_response_no_context], references=[reference_response])\n",
        "  print(\"\\nğŸ”¹ ROUGE score (Gemini without context):\")\n",
        "  for key, value in rouge_score_no_context.items():\n",
        "      print(f\"- {key}: {value:.4f}\")\n",
        "\n",
        "  return bleu_score_no_context, rouge_score_no_context"
      ],
      "metadata": {
        "id": "IFWcF9eP-1x5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "877e8005",
        "outputId": "4f52f72e-051f-4698-d5e8-694623ebeb60"
      },
      "source": [
        "# ========= 8. COMPARACIÃ“N E INTERPRETACIÃ“N DE RESULTADOS =========\n",
        "\n",
        "print(\"\\n=== ComparaciÃ³n e InterpretaciÃ³n de las MÃ©tricas ===\")\n",
        "\n",
        "print(\"\\nComparando las respuestas generadas con la referencia (ChatGPT):\")\n",
        "\n",
        "bue_score_context, rouge_score_context = evaluate_response(response, response_chat)\n",
        "bue_score_no_context, rouge_score_no_context = evaluate_response_no_context(response_no_context, response_chat)\n",
        "\n",
        "# Compare BLEU scores\n",
        "print(\"\\nResultados BLEU:\")\n",
        "print(f\"- Gemini con contexto (BLEU): {bleu_score_context['bleu']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (BLEU): {bleu_score_no_context['bleu']:.4f}\")\n",
        "\n",
        "if bleu_score_context['bleu'] > bleu_score_no_context['bleu']:\n",
        "    print(\"  -> SegÃºn el BLEU score general, la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif bleu_score_context['bleu'] < bleu_score_no_context['bleu']:\n",
        "     print(\"  -> SegÃºn el BLEU score general, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los BLEU scores generales son similares.\")\n",
        "\n",
        "print(\"\\nResultados ROUGE:\")\n",
        "print(f\"- Gemini con contexto (ROUGE-1): {rouge_score_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-1): {rouge_score_no_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini con contexto (ROUGE-L): {rouge_score_context['rougeL']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-L): {rouge_score_no_context['rougeL']:.4f}\")\n",
        "\n",
        "\n",
        "if rouge_score_context['rouge1'] > rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> SegÃºn ROUGE-1 (superposiciÃ³n de palabras individuales), la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif rouge_score_context['rouge1'] < rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> SegÃºn ROUGE-1, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los ROUGE-1 scores son similares.\")\n",
        "\n",
        "if rouge_score_context['rougeL'] > rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> SegÃºn ROUGE-L (subsecuencia mÃ¡s larga, sensible al orden), la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif rouge_score_context['rougeL'] < rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> SegÃºn ROUGE-L, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "     print(\"  -> Los ROUGE-L scores son similares.\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ComparaciÃ³n e InterpretaciÃ³n de las MÃ©tricas ===\n",
            "\n",
            "Comparando las respuestas generadas con la referencia (ChatGPT):\n",
            "\n",
            "ğŸ”¹ BLEU score (Gemini with context): 0.0000\n",
            "ğŸ”¹ BLEU precision scores (Gemini with context):\n",
            "- Precision@1: 0.0737\n",
            "- Precision@2: 0.0080\n",
            "- Precision@3: 0.0000\n",
            "- Precision@4: 0.0000\n",
            "\n",
            "ğŸ”¹ ROUGE score (Gemini with context):\n",
            "- rouge1: 0.1957\n",
            "- rouge2: 0.0164\n",
            "- rougeL: 0.1196\n",
            "- rougeLsum: 0.1359\n",
            "\n",
            "ğŸ”¹ BLEU score (Gemini without context): 0.1400\n",
            "\n",
            "ğŸ”¹ ROUGE score (Gemini without context):\n",
            "- rouge1: 0.5387\n",
            "- rouge2: 0.2751\n",
            "- rougeL: 0.2731\n",
            "- rougeLsum: 0.2731\n",
            "\n",
            "Resultados BLEU:\n",
            "- Gemini con contexto (BLEU): 0.0904\n",
            "- Gemini sin contexto (BLEU): 0.0896\n",
            "  -> SegÃºn el BLEU score general, la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\n",
            "\n",
            "Resultados ROUGE:\n",
            "- Gemini con contexto (ROUGE-1): 0.1957\n",
            "- Gemini sin contexto (ROUGE-1): 0.5387\n",
            "- Gemini con contexto (ROUGE-L): 0.1196\n",
            "- Gemini sin contexto (ROUGE-L): 0.2731\n",
            "  -> SegÃºn ROUGE-1, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\n",
            "  -> SegÃºn ROUGE-L, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyQtSj8YhcW3"
      },
      "source": [
        "# 2. **GraphRAG con Gemini + Neo4j: Consultando Grafos de Conocimiento:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tkzFK1bhYG7"
      },
      "source": [
        "En este ejemplo usamos Gemini para extraer triples semÃ¡nticos del texto (por ejemplo: (Elon Musk, fundÃ³, Tesla)).\n",
        "\n",
        "Luego esos triples se guardan en Neo4j, una base de datos orientada a grafos.\n",
        "DespuÃ©s, podemos hacer consultas usando Cypher, el lenguaje de Neo4j, y finalmente Gemini genera una respuesta en lenguaje natural usando la informaciÃ³n consultada.\n",
        "\n",
        "Esto permite transformar un texto plano en un grafo de conocimiento consultable, lo que es muy Ãºtil para preguntas complejas que requieren relaciones entre entidades."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiMLgjeuvQqs"
      },
      "source": [
        "## **PreparaciÃ³n del entorno:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EDSiOHMvROs"
      },
      "source": [
        "Antes de ejecutar el cÃ³digo:\n",
        "\n",
        "1. **Cuenta en Neo4j AuraDB (gratis): https://neo4j.com/product/auradb/**\n",
        "\n",
        "- Ir a Neo4j AuraDB Free.\n",
        "\n",
        "- Crear una cuenta y una base de datos gratuita.\n",
        "\n",
        "- Copiar los datos de conexiÃ³n (URI, Usuario, ContraseÃ±a).\n",
        "\n",
        "**âš ï¸ Este paso, al igual que la creaciÃ³n de la API Key de Gemini, solo serÃ¡ necesario si las credenciales ya incluidas en el cÃ³digo no funcionan.\n",
        "De esta manera, cada estudiante tendrÃ¡ la opciÃ³n de usar sus propias credenciales y su propia base de datos personalizada en caso de que sea necesario.**\n",
        "\n",
        "2. **Nuevamente tener presente los archivos disponibles en Drive:https://drive.google.com/drive/folders/1uF7-oSMpzSdID2ltQf9NsU5Snf16fHfx?usp=sharing**\n",
        "\n",
        "- cuantica.txt â†’ introducciÃ³n a la fÃ­sica cuÃ¡ntica. **(Usado en al demo en clase)**.\n",
        "\n",
        "- innovadores.txt â†’ introducciÃ³n a la fÃ­sica cuÃ¡ntica. **(Usado en al demo en clase)**.\n",
        "\n",
        "- historia_Colombia.txt â†’ texto sobre historia de Colombia.\n",
        "\n",
        "- historia_internet.txt â†’ documento con explicaciÃ³n bÃ¡sica de Einstein.\n",
        "\n",
        "ğŸ‘‰ **Suban uno de estos archivos (o el suyo propio) cuando el cÃ³digo lo pida.****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46Y4MlqqwSv5"
      },
      "source": [
        "## **Snippets de Cypher para practicar**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpIzHKKVwl-Q"
      },
      "source": [
        "Los estudiantes pueden reemplazar el query y la pregunta con estos ejemplos (COPIAR Y PEGAR EN EL BLOQUE DE CODIGO DEL GRAPHRAG):\n",
        "\n",
        "### **Para el documento innovadores.txt disponible en google drive:** Â¿CuÃ¡les son las empresas fundadas por Elon Musk y por Steve Jobs, a quÃ© se dedica cada una y por quÃ© es importante lo que hacen?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "EZ-LhlWxxJMv"
      },
      "outputs": [],
      "source": [
        "cypher_query = \"\"\"\n",
        "MATCH (p:Entidad)-[r:RELACION]->(c:Entidad)\n",
        "RETURN p.name AS persona, r.tipo AS relacion, c.nameÂ ASÂ compania\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx_BWVFnyQx2"
      },
      "source": [
        "### **Para el documento hisotria_internet.txt disponible en google drive:** Â¿CuÃ¡l fue la importancia de Tim Berners-Lee en la historia de Internet?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yqHm3eEwyOeM"
      },
      "outputs": [],
      "source": [
        "cypher_query = \"\"\"\n",
        "MATCH (a:Entidad)-[r:RELACION]->(b:Entidad)\n",
        "WHERE a.name = \"Tim Berners-Lee\"\n",
        "RETURN a.name AS a, r.tipo AS relacion, b.name AS b\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6KFM7pFpghrn",
        "outputId": "7caa7aa5-0ddb-4794-f973-65efa779d4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.12/dist-packages (5.28.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from neo4j) (2025.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.182.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n",
            "Sube un archivo de texto con informaciÃ³n (ej: innovadores.txt)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-78ecf771-3df7-44db-b18f-52a7837a6ac1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-78ecf771-3df7-44db-b18f-52a7837a6ac1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving innovadores.txt to innovadores (8).txt\n",
            "ğŸ”¹ Triples extraÃ­dos por Gemini:\n",
            "AquÃ­ tienes las relaciones extraÃ­das del texto en formato de triples (SUJETO, RELACIÃ“N, OBJETO):\n",
            "\n",
            "* (Elon Musk, fundÃ³, Tesla)\n",
            "* (Tesla, tipo_de_compaÃ±Ã­a, fabricante de automÃ³viles elÃ©ctricos)\n",
            "* (Tesla, se_dedica_a, soluciones de energÃ­a renovable)\n",
            "* (Elon Musk, fundÃ³, SpaceX)\n",
            "* (SpaceX, tipo_de_empresa, empresa de exploraciÃ³n espacial)\n",
            "* (SpaceX, desarrolla, cohetes)\n",
            "* (SpaceX, desarrolla, satÃ©lites)\n",
            "* (Elon Musk, participÃ³_en_la_creaciÃ³n_de, PayPal)\n",
            "* (PayPal, tipo_de_sistema, sistema de pagos en lÃ­nea)\n",
            "* (PayPal, revolucionÃ³, transacciones digitales)\n",
            "* (Steve Jobs, fue_cofundador_de, Apple)\n",
            "* (Apple, reconocida_por, productos tecnolÃ³gicos innovadores)\n",
            "* (Apple, desarrollÃ³, iPhone)\n",
            "* (Apple, desarrollÃ³, iPad)\n",
            "* (Apple, desarrollÃ³, MacBook)\n",
            "* (Apple, fue_clave_en, desarrollo de la industria de los dispositivos inteligentes)\n",
            "* (Jeff Bezos, fundÃ³, Amazon)\n",
            "* (Amazon, inicio_como, librerÃ­a en lÃ­nea)\n",
            "* (Amazon, evolucionÃ³_hacia, plataforma de comercio electrÃ³nico)\n",
            "* (Amazon, ofrece, servicios en la nube)\n",
            "* (Amazon, servicio_en_la_nube, Amazon Web Services (AWS))\n",
            "* (Mark Zuckerberg, creÃ³, Facebook)\n",
            "* (Facebook, tipo_de_red, red social)\n",
            "* (Facebook, transformÃ³, comunicaciÃ³n digital)\n",
            "* (Facebook, transformÃ³, publicidad)\n",
            "* (Facebook, transformÃ³, interacciÃ³n en lÃ­nea)\n",
            "* (Larry Page, fundÃ³, Google)\n",
            "* (Sergey Brin, fundÃ³, Google)\n",
            "* (Google, tipo_de_servicio, motor de bÃºsqueda)\n",
            "* (Google, cambiÃ³, acceso a la informaciÃ³n global)\n",
            "* (Google, desarrollÃ³, Android)\n",
            "* (Android, tipo_de_sistema, sistema operativo)\n",
            "* (Android, uso_en, telÃ©fonos inteligentes)\n",
            "* (Android, sistema_operativo_mas_usado, telÃ©fonos inteligentes)\n",
            "\n",
            "\n",
            "He tratado de ser lo mÃ¡s preciso posible, usando relaciones que reflejen el significado del texto.  Algunas relaciones podrÃ­an ser mÃ¡s especÃ­ficas o detalladas dependiendo del contexto y del nivel de granularidad requerido.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4281262237.py:61: DeprecationWarning: write_transaction has been renamed to execute_write\n",
            "  session.write_transaction(insert_triple, s, r, o)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Se insertaron 35 triples en Neo4j\n",
            "\n",
            "ğŸ”¹ Resultados de la consulta Cypher:\n",
            "* **(Elon Musk fundÃ³ Tesla)**\n",
            "* **(Tesla tipo_de_compaÃ±Ã­a fabricante de automÃ³viles elÃ©ctricos y soluciones de energÃ­a renovable)**\n",
            "* **(Elon Musk fundÃ³ SpaceX)**\n",
            "* **(SpaceX tipo_de_empresa empresa de exploraciÃ³n espacial)**\n",
            "* **(SpaceX desarrolla cohetes y satÃ©lites)**\n",
            "* **(Elon Musk participÃ³_en_la_creaciÃ³n PayPal)**\n",
            "* **(PayPal tipo_de_servicio sistema de pagos en lÃ­nea)**\n",
            "* **(Steve Jobs cofundÃ³ Apple)**\n",
            "* **(Apple tipo_de_empresa empresa reconocida por sus productos tecnolÃ³gicos innovadores)**\n",
            "* **(Apple desarrollÃ³ iPhone)**\n",
            "* **(Apple desarrollÃ³ iPad)**\n",
            "* **(Apple desarrollÃ³ MacBook)**\n",
            "* **(Apple clave_en_el_desarrollo industria de los dispositivos inteligentes)**\n",
            "* **(Jeff Bezos fundÃ³ Amazon)**\n",
            "* **(Amazon inicio_como librerÃ­a en lÃ­nea)**\n",
            "* **(Amazon evolucionÃ³_a plataforma de comercio electrÃ³nico y servicios en la nube)**\n",
            "* **(Amazon ofrece Amazon Web Services (AWS))**\n",
            "* **(Mark Zuckerberg creÃ³ Facebook)**\n",
            "* **(Facebook tipo_de_plataforma red social)**\n",
            "* **(Facebook transformÃ³ comunicaciÃ³n digital)**\n",
            "* **(Facebook transformÃ³ publicidad)**\n",
            "* **(Facebook transformÃ³ interacciÃ³n en lÃ­nea)**\n",
            "* **(Larry Page fundÃ³ Google)**\n",
            "* **(Sergey Brin fundÃ³ Google)**\n",
            "* **(Google tipo_de_servicio motor de bÃºsqueda)**\n",
            "* **(Google desarrollÃ³ Android)**\n",
            "* **(Android tipo_de_sistema sistema operativo)**\n",
            "* **(Android uso telÃ©fonos inteligentes)**\n",
            "* (Elon Musk fundÃ³ Tesla\n",
            "* (Tesla es compaÃ±Ã­a de automÃ³viles elÃ©ctricos y soluciones de energÃ­a renovable\n",
            "* (Elon Musk fundÃ³ SpaceX\n",
            "* (SpaceX es empresa de exploraciÃ³n espacial\n",
            "* (SpaceX tipo_de_empresa empresa de exploraciÃ³n espacial\n",
            "* (SpaceX desarrolla cohetes y satÃ©lites\n",
            "* (Elon Musk participÃ³ en la creaciÃ³n de PayPal\n",
            "* (Elon Musk participÃ³_en_la_creaciÃ³n_de PayPal\n",
            "* (PayPal es sistema de pagos en lÃ­nea\n",
            "* (PayPal tipo_de_sistema sistema de pagos en lÃ­nea\n",
            "* (PayPal revolucionÃ³ transacciones digitales\n",
            "* (Steve Jobs fue cofundador de Apple\n",
            "* (Steve Jobs cofundÃ³ Apple\n",
            "* (Steve Jobs fue_cofundador_de Apple\n",
            "* (Apple es empresa de productos tecnolÃ³gicos innovadores\n",
            "* (Apple fue clave en el desarrollo de industria de los dispositivos inteligentes\n",
            "* (Jeff Bezos fundÃ³ Amazon\n",
            "* (Amazon fue inicialmente librerÃ­a en lÃ­nea\n",
            "* (Amazon inicio_como librerÃ­a en lÃ­nea\n",
            "* (Amazon evolucionÃ³ hacia plataforma de comercio electrÃ³nico y servicios en la nube\n",
            "* (Amazon ofrece Amazon Web Services (AWS\n",
            "* (Amazon servicio Amazon Web Services (AWS\n",
            "* (Amazon servicio_en_la_nube Amazon Web Services (AWS\n",
            "* (Mark Zuckerberg creÃ³ Facebook\n",
            "* (Larry Page fundÃ³ Google\n",
            "* (Sergey Brin fundÃ³ Google\n",
            "* (Google es motor de bÃºsqueda\n",
            "* (Google tipo_de_servicio motor de bÃºsqueda\n",
            "* (Google cambiÃ³ acceso a la informaciÃ³n global\n",
            "* (Google desarrollÃ³ Android\n",
            "* (Android es sistema operativo para telÃ©fonos inteligentes\n",
            "* (Android es sistema operativo mÃ¡s utilizado en telÃ©fonos inteligentes\n",
            "AquÃ­ tienes las relaciones extraÃ­das del texto en formato de triples (SUJETO RELACIÃ“N OBJETO):\n",
            "* (Tesla tipo_de_compaÃ±Ã­a fabricante de automÃ³viles elÃ©ctricos\n",
            "* (Tesla se_dedica_a soluciones de energÃ­a renovable\n",
            "* (SpaceX desarrolla cohetes\n",
            "* (SpaceX desarrolla satÃ©lites\n",
            "* (Apple reconocida_por productos tecnolÃ³gicos innovadores\n",
            "* (Apple desarrollÃ³ iPhone\n",
            "* (Apple desarrollÃ³ iPad\n",
            "* (Apple desarrollÃ³ MacBook\n",
            "* (Apple clave_en desarrollo de la industria de los dispositivos inteligentes\n",
            "* (Apple fue_clave_en desarrollo de la industria de los dispositivos inteligentes\n",
            "* (Amazon evolucionÃ³_a plataforma de comercio electrÃ³nico\n",
            "* (Amazon evolucionÃ³_hacia plataforma de comercio electrÃ³nico\n",
            "* (Amazon ofrece servicios en la nube\n",
            "* (Facebook tipo_de_red red social\n",
            "* (Facebook transformÃ³ comunicaciÃ³n digital\n",
            "* (Facebook transformÃ³ publicidad\n",
            "* (Facebook transformÃ³ interacciÃ³n en lÃ­nea\n",
            "* (Android tipo_de_sistema sistema operativo\n",
            "* (Android sistema_operativo_mÃ¡s_utilizado telÃ©fonos inteligentes\n",
            "* (Android uso_en telÃ©fonos inteligentes\n",
            "* (Android sistema_operativo_mas_usado telÃ©fonos inteligentes\n",
            "\n",
            "ğŸ”¹ Respuesta generada por Gemini:\n",
            "Elon Musk fundÃ³ Tesla y SpaceX.\n",
            "\n",
            "* **Tesla:** Es una compaÃ±Ã­a fabricante de automÃ³viles elÃ©ctricos y soluciones de energÃ­a renovable.  Su importancia radica en su contribuciÃ³n a la mitigaciÃ³n del cambio climÃ¡tico a travÃ©s del desarrollo de vehÃ­culos elÃ©ctricos y tecnologÃ­as de energÃ­a limpia, impulsando una transiciÃ³n hacia una movilidad y energÃ­a mÃ¡s sostenibles.\n",
            "\n",
            "* **SpaceX:** Es una empresa de exploraciÃ³n espacial que desarrolla cohetes y satÃ©lites. Su importancia reside en su ambiciÃ³n de reducir los costos de acceso al espacio,  facilitando la exploraciÃ³n espacial y abriendo nuevas posibilidades para la investigaciÃ³n cientÃ­fica, la comunicaciÃ³n satelital y la colonizaciÃ³n espacial.\n",
            "\n",
            "\n",
            "Steve Jobs fue cofundador de Apple.\n",
            "\n",
            "* **Apple:** Es una empresa reconocida por sus productos tecnolÃ³gicos innovadores como el iPhone, iPad y MacBook.  Su importancia se debe a su papel clave en el desarrollo de la industria de los dispositivos inteligentes, revolucionando la forma en que interactuamos con la tecnologÃ­a y creando un ecosistema de productos altamente integrado e influyente en el mercado global.  Su impacto se extiende a la creaciÃ³n de una cultura de diseÃ±o centrada en el usuario y a la definiciÃ³n de estÃ¡ndares en la industria tecnolÃ³gica.\n",
            "\n",
            "\n",
            "ğŸ”¹ Respuesta generada por Gemini sin contexto:\n",
            "No puedo responder a esta pregunta sin el contexto del grafo de conocimiento.  Necesito la informaciÃ³n contenida en el grafo para identificar las empresas fundadas por Elon Musk y Steve Jobs, sus actividades y la importancia de las mismas.  Por favor, proporcione el grafo de conocimiento.\n",
            "\n",
            "\n",
            "ğŸ”¹ Respuesta generada por Chatgpt:\n",
            "El cientÃ­fico que propuso un modelo atÃ³mico en **1913 fue Niels Bohr**. Bohr planteÃ³ que los electrones orbitan alrededor del nÃºcleo en niveles de energÃ­a cuantizados, lo que permitiÃ³ explicar fenÃ³menos como las lÃ­neas espectrales del hidrÃ³geno. Este modelo fue un gran avance respecto al de Rutherford, ya que incorporÃ³ ideas de la teorÃ­a cuÃ¡ntica para describir la estabilidad del Ã¡tomo. De manera adicional, aunque luego fue superado por la mecÃ¡nica cuÃ¡ntica de SchrÃ¶dinger y Heisenberg, el modelo de Bohr sigue siendo muy Ãºtil en la enseÃ±anza porque introduce de forma sencilla el concepto de niveles de energÃ­a y la transiciÃ³n de electrones con emisiÃ³n o absorciÃ³n de fotones.\n"
          ]
        }
      ],
      "source": [
        "# ================== INSTALACIÃ“N ==================\n",
        "!pip install neo4j google-generativeai\n",
        "\n",
        "import os\n",
        "from neo4j import GraphDatabase\n",
        "import google.generativeai as genai\n",
        "from google.colab import files\n",
        "\n",
        "# ================== CONFIGURACIÃ“N ==================\n",
        "# ğŸ‘‰ API Key de Gemini (puede usar la nuestra o crear la suya en https://aistudio.google.com/)\"\n",
        "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "\n",
        "# ğŸ‘‰ Configura Neo4j con tus propios datos (SOLO si falla la configuraciÃ³n por defecto del Colab)\n",
        "NEO4J_URI = userdata.get('urlneo')\n",
        "NEO4J_USER = \"neo4j\"\n",
        "NEO4J_PASSWORD = userdata.get('neo4j')\n",
        "\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
        "\n",
        "# ================== SUBIR DOCUMENTO ==================\n",
        "print(\"Sube un archivo de texto con informaciÃ³n (ej: innovadores.txt)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# ================== EXTRAER TRIPLES CON GEMINI ==================\n",
        "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Extrae relaciones del siguiente texto en formato de triples:\n",
        "(SUJETO, RELACIÃ“N, OBJETO).\n",
        "Texto:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(\"ğŸ”¹ Triples extraÃ­dos por Gemini:\")\n",
        "print(response.text)\n",
        "\n",
        "# ================== GUARDAR TRIPLES EN NEO4J ==================\n",
        "def insert_triple(tx, s, r, o):\n",
        "    query = \"\"\"\n",
        "    MERGE (a:Entidad {name: $s})\n",
        "    MERGE (b:Entidad {name: $o})\n",
        "    MERGE (a)-[rel:RELACION {tipo: $r}]->(b)\n",
        "    \"\"\"\n",
        "    tx.run(query, s=s, r=r, o=o)\n",
        "\n",
        "triples = []\n",
        "for line in response.text.split(\"\\n\"):\n",
        "    if \"(\" in line and \")\" in line:\n",
        "        line = line.strip(\"()\")\n",
        "        parts = [p.strip() for p in line.split(\",\")]\n",
        "        if len(parts) == 3:\n",
        "            triples.append(parts)\n",
        "\n",
        "with driver.session() as session:\n",
        "    for s, r, o in triples:\n",
        "        session.write_transaction(insert_triple, s, r, o)\n",
        "\n",
        "print(f\"âœ… Se insertaron {len(triples)} triples en Neo4j\")\n",
        "\n",
        "# ================== CONSULTA AL GRAFO ==================\n",
        "def query_graph(query):\n",
        "    with driver.session() as session:\n",
        "        result = session.run(query)\n",
        "        return [dict(r) for r in result]\n",
        "\n",
        "# AQUI PUEDEN CAMBIAR LAS QUERY POR LOS EJEMPLOS DE ARRIBA ============================== â°â°â° =============================\n",
        "cypher_query = \"\"\"\n",
        "MATCH (p:Entidad)-[r:RELACION]->(c:Entidad)\n",
        "RETURN p.name AS persona, r.tipo AS relacion, c.nameÂ ASÂ compania\n",
        "\"\"\"\n",
        "\n",
        "results = query_graph(cypher_query)\n",
        "\n",
        "print(\"\\nğŸ”¹ Resultados de la consulta Cypher:\")\n",
        "for r in results:\n",
        "    print(f\"{r['persona']} {r['relacion']} {r['compania']}\")\n",
        "\n",
        "# ================== GEMINI PARA RESPUESTA FINAL ==================\n",
        "context = \"\\n\".join([f\"{r['persona']} {r['relacion']} {r['compania']}\" for r in results])\n",
        "\n",
        "# AQUI PUEDEN CAMBIAR LAS PREGUNTAS POR LOS EJEMPLOS DE ARRIBA ============================== â°â°â° =============================\n",
        "\n",
        "final_prompt = f\"\"\"\n",
        "BasÃ¡ndote en el siguiente contexto de un grafo de conocimiento, responde la pregunta y proporciona contexto:\n",
        "\n",
        "Contexto:\n",
        "{context}\n",
        "\n",
        "Pregunta:  Â¿CuÃ¡les son las empresas fundadas por Elon Musk y por Steve Jobs, a quÃ© se dedica cada una y por quÃ© es importante lo que hacen?\n",
        "\"\"\"\n",
        "\n",
        "final_prompt_no_context = f\"\"\"\n",
        "BasÃ¡ndote en el siguiente contexto de un grafo de conocimiento, responde la pregunta y proporciona contexto:\n",
        "\n",
        "Pregunta:  Â¿CuÃ¡les son las empresas fundadas por Elon Musk y por Steve Jobs, a quÃ© se dedica cada una y por quÃ© es importante lo que hacen?\n",
        "\"\"\"\n",
        "\n",
        "response_final = model.generate_content(final_prompt)\n",
        "\n",
        "response_no_context = model.generate_content(final_prompt_no_context)\n",
        "\n",
        "respuesta_chat = \"\"\"Elon Musk fundÃ³ Tesla y SpaceX, ademÃ¡s de participar en la creaciÃ³n de PayPal.\n",
        "\n",
        "* **Tesla:** Es una compaÃ±Ã­a dedicada a la fabricaciÃ³n de automÃ³viles elÃ©ctricos y soluciones de energÃ­a renovable. Su importancia radica en su contribuciÃ³n a la lucha contra el cambio climÃ¡tico mediante la promociÃ³n de vehÃ­culos elÃ©ctricos y energÃ­as limpias, ademÃ¡s de impulsar la innovaciÃ³n en el sector automotriz.\n",
        "\n",
        "* **SpaceX:** Es una empresa de exploraciÃ³n espacial que desarrolla y lanza cohetes y satÃ©lites. Su importancia reside en su objetivo de reducir los costos del acceso al espacio, facilitar la colonizaciÃ³n de Marte y promover la innovaciÃ³n tecnolÃ³gica en el sector aeroespacial. Contribuye a la exploraciÃ³n espacial y al desarrollo de nuevas tecnologÃ­as.\n",
        "\n",
        "* **PayPal:** Es un sistema de pagos en lÃ­nea que transformÃ³ la manera en que se realizan transacciones digitales. Su importancia se encuentra en haber ofrecido una forma segura, rÃ¡pida y global de realizar pagos por internet, siendo pionera en la economÃ­a digital.\n",
        "\n",
        "Steve Jobs fue cofundador de Apple.\n",
        "\n",
        "* **Apple:** Es una empresa reconocida por sus productos tecnolÃ³gicos innovadores como el iPhone, iPad y MacBook. Su importancia se debe a su influencia en la industria de los dispositivos inteligentes, al establecer estÃ¡ndares de diseÃ±o y usabilidad, y revolucionar la manera en que las personas interactÃºan con la tecnologÃ­a. Ha sido clave en el desarrollo de esta industria, popularizando conceptos como la interfaz grÃ¡fica intuitiva y la integraciÃ³n de software y hardware.\"\"\"\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada por Gemini:\")\n",
        "print(response_final.text)\n",
        "\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada por Gemini sin contexto:\")\n",
        "print(response_no_context.text)\n",
        "\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada por Chatgpt:\")\n",
        "print(response_chat)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MÃ©tricas de evaluaciÃ³n"
      ],
      "metadata": {
        "id": "lbWjtnEpQW-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 8. COMPARACIÃ“N E INTERPRETACIÃ“N DE RESULTADOS =========\n",
        "\n",
        "print(\"\\n=== ComparaciÃ³n e InterpretaciÃ³n de las MÃ©tricas ===\")\n",
        "\n",
        "print(\"\\nComparando las respuestas generadas con la referencia (ChatGPT):\")\n",
        "\n",
        "bue_score_context, rouge_score_context = evaluate_response(response, respuesta_chat)\n",
        "bue_score_no_context, rouge_score_no_context = evaluate_response_no_context(response_no_context, respuesta_chat)\n",
        "\n",
        "# Compare BLEU scores\n",
        "print(\"\\nResultados BLEU:\")\n",
        "print(f\"- Gemini con contexto (BLEU): {bleu_score_context['bleu']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (BLEU): {bleu_score_no_context['bleu']:.4f}\")\n",
        "\n",
        "if bleu_score_context['bleu'] > bleu_score_no_context['bleu']:\n",
        "    print(\"  -> SegÃºn el BLEU score general, la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif bleu_score_context['bleu'] < bleu_score_no_context['bleu']:\n",
        "     print(\"  -> SegÃºn el BLEU score general, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los BLEU scores generales son similares.\")\n",
        "\n",
        "print(\"\\nResultados ROUGE:\")\n",
        "print(f\"- Gemini con contexto (ROUGE-1): {rouge_score_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-1): {rouge_score_no_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini con contexto (ROUGE-L): {rouge_score_context['rougeL']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-L): {rouge_score_no_context['rougeL']:.4f}\")\n",
        "\n",
        "\n",
        "if rouge_score_context['rouge1'] > rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> SegÃºn ROUGE-1 (superposiciÃ³n de palabras individuales), la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif rouge_score_context['rouge1'] < rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> SegÃºn ROUGE-1, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los ROUGE-1 scores son similares.\")\n",
        "\n",
        "if rouge_score_context['rougeL'] > rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> SegÃºn ROUGE-L (subsecuencia mÃ¡s larga, sensible al orden), la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif rouge_score_context['rougeL'] < rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> SegÃºn ROUGE-L, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "     print(\"  -> Los ROUGE-L scores son similares.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eXr6mx3OJNy",
        "outputId": "cafd2cd1-0c4b-4af6-e3bb-6c5d2a11ea52"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ComparaciÃ³n e InterpretaciÃ³n de las MÃ©tricas ===\n",
            "\n",
            "Comparando las respuestas generadas con la referencia (ChatGPT):\n",
            "\n",
            "ğŸ”¹ BLEU score (Gemini with context): 0.0000\n",
            "ğŸ”¹ BLEU precision scores (Gemini with context):\n",
            "- Precision@1: 0.0960\n",
            "- Precision@2: 0.0067\n",
            "- Precision@3: 0.0000\n",
            "- Precision@4: 0.0000\n",
            "\n",
            "ğŸ”¹ ROUGE score (Gemini with context):\n",
            "- rouge1: 0.2222\n",
            "- rouge2: 0.0260\n",
            "- rougeL: 0.1292\n",
            "- rougeLsum: 0.1499\n",
            "\n",
            "ğŸ”¹ BLEU score (Gemini without context): 0.0000\n",
            "\n",
            "ğŸ”¹ ROUGE score (Gemini without context):\n",
            "- rouge1: 0.1965\n",
            "- rouge2: 0.0117\n",
            "- rougeL: 0.1272\n",
            "- rougeLsum: 0.1272\n",
            "\n",
            "Resultados BLEU:\n",
            "- Gemini con contexto (BLEU): 0.0904\n",
            "- Gemini sin contexto (BLEU): 0.0896\n",
            "  -> SegÃºn el BLEU score general, la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\n",
            "\n",
            "Resultados ROUGE:\n",
            "- Gemini con contexto (ROUGE-1): 0.2222\n",
            "- Gemini sin contexto (ROUGE-1): 0.1965\n",
            "- Gemini con contexto (ROUGE-L): 0.1292\n",
            "- Gemini sin contexto (ROUGE-L): 0.1272\n",
            "  -> SegÃºn ROUGE-1 (superposiciÃ³n de palabras individuales), la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\n",
            "  -> SegÃºn ROUGE-L (subsecuencia mÃ¡s larga, sensible al orden), la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df4UpK7chNL3"
      },
      "source": [
        "# 3. **FusionRAG (BM25 + Embeddings)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9VZtHlqhMXn"
      },
      "source": [
        "En este ejemplo se combina lo mejor de dos enfoques de recuperaciÃ³n de informaciÃ³n:\n",
        "\n",
        "- BM25 (keyword-based): Recupera pasajes basÃ¡ndose en la coincidencia de palabras clave.\n",
        "\n",
        "- Vector Search (embeddings con ChromaDB): Recupera fragmentos usando similitud semÃ¡ntica.\n",
        "\n",
        "Ambos resultados se fusionan para obtener un contexto mÃ¡s robusto y completo, que luego se pasa al modelo Gemini para generar una respuesta.\n",
        "\n",
        "ğŸ‘‰ Deben subir un archivo de texto (ej: cuantica.txt, historia_colombia.txt, innovadores.txt o historia_internet.txt) y luego probar con diferentes preguntas modificando el campo query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF1FWJa_0GIg"
      },
      "source": [
        "## **PreparaciÃ³n del entorno:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9avBZ7T00GlQ"
      },
      "source": [
        "Si ya configuraste los entornos de los ejemplos anteriores, no necesitas hacer nada adicional para este bloque. ğŸš€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "s7Q2HHrgeQSM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e50a3040-779e-40ff-b274-341a19aa8d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.22.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.17.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.182.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "ğŸ“‚ Sube un archivo de texto con informaciÃ³n (ej: cuantica.txt, historia_colombia.txt, etc.)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e5f10283-8939-4c7c-b45c-601f005b4905\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e5f10283-8939-4c7c-b45c-601f005b4905\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cuantica.txt to cuantica (3).txt\n",
            "\n",
            "ğŸ”¹ Respuesta generada con FusionRAG:\n",
            "Niels Bohr propuso un modelo atÃ³mico en 1913.  El texto explÃ­citamente menciona que en ese aÃ±o, Bohr propuso su modelo atÃ³mico donde los electrones orbitaban en niveles de energÃ­a cuantizados alrededor del nÃºcleo.  La informaciÃ³n sobre la independencia de Colombia es irrelevante para responder a esta pregunta especÃ­fica.\n",
            "\n",
            "\n",
            "ğŸ”¹ Respuesta generada por Gemini sin contexto:\n",
            "El cientÃ­fico que propuso un modelo atÃ³mico en 1913 fue **Niels Bohr**.\n",
            "\n",
            "La explicaciÃ³n reside en que el modelo atÃ³mico de Bohr, publicado en 1913,  fue una mejora significativa al modelo de Rutherford.  Si bien el modelo de Rutherford describiÃ³ correctamente la existencia de un nÃºcleo atÃ³mico positivo con electrones orbitÃ¡ndolo, no explicaba la estabilidad del Ã¡tomo.  El modelo de Bohr incorporÃ³ la teorÃ­a cuÃ¡ntica de Planck, postulando que los electrones orbitan el nÃºcleo en Ã³rbitas especÃ­ficas con niveles de energÃ­a definidos, y que los electrones solo pueden saltar entre estas Ã³rbitas absorbiendo o emitiendo fotones de energÃ­a especÃ­fica.  Esto solucionaba el problema de la inestabilidad del modelo de Rutherford, ya que impedÃ­a que los electrones cayeran en el nÃºcleo.  Por lo tanto, el modelo de Bohr de 1913 es un hito en la historia de la fÃ­sica atÃ³mica.\n",
            "\n",
            "\n",
            "ğŸ”¹ Respuesta generada por Chatgpt:\n",
            "El cientÃ­fico que propuso un modelo atÃ³mico en 1913 fue Niels Bohr\n",
            "\n",
            "Bohr planteÃ³ que los electrones no podÃ­an ocupar cualquier Ã³rbita alrededor del nÃºcleo, sino que se encontraban en niveles de energÃ­a cuantizados. Esto significaba que los electrones solo podÃ­an moverse entre niveles discretos, emitiendo o absorbiendo energÃ­a en forma de cuantos (fotones). Su modelo fue una mejora respecto al de Rutherford, ya que explicaba fenÃ³menos como el espectro del hidrÃ³geno, donde las lÃ­neas de emisiÃ³n correspondÃ­an a transiciones electrÃ³nicas entre estos niveles.\n",
            "\n",
            "Este aporte fue crucial porque introdujo el concepto de cuantizaciÃ³n al modelo atÃ³mico, conectando las ideas de Planck y Einstein con la estructura de la materia, y sentando las bases de la mecÃ¡nica cuÃ¡ntica moderna.\n"
          ]
        }
      ],
      "source": [
        "# ================= DEMO FUSION RAG ==================\n",
        "!pip install rank_bm25 chromadb sentence-transformers google-generativeai\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# ================= SUBIR DOCUMENTO ==================\n",
        "print(\"ğŸ“‚ Sube un archivo de texto con informaciÃ³n (ej: cuantica.txt, historia_colombia.txt, etc.)\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "file_name = list(uploaded.keys())[0]\n",
        "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "# ================= CHUNKING ==================\n",
        "def chunk_text(text, chunk_size=80, overlap=20):\n",
        "    words = text.split()\n",
        "    return [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size - overlap)]\n",
        "\n",
        "docs = chunk_text(text)\n",
        "\n",
        "# ========= Vector Store (embeddings con ChromaDB)\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "client = chromadb.Client()\n",
        "collection = client.get_or_create_collection(\"fusion_chunks\")\n",
        "embeddings = embedder.encode(docs).tolist()\n",
        "for i, d in enumerate(docs):\n",
        "    collection.add(documents=[d], embeddings=[embeddings[i]], ids=[str(i)])\n",
        "\n",
        "# ========= BM25 retriever\n",
        "tokenized_corpus = [d.split(\" \") for d in docs]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# ========= Fusion Retrieval\n",
        "query = \"Â¿QuÃ© cientÃ­fico propuso un modelo atÃ³mico en 1913?\"\n",
        "q_embed = embedder.encode([query]).tolist()\n",
        "results_vector = collection.query(query_embeddings=q_embed, n_results=3)\n",
        "results_bm25 = bm25.get_top_n(query.split(\" \"), docs, n=3)\n",
        "\n",
        "# FusiÃ³n (simple: concatenaciÃ³n + eliminaciÃ³n de duplicados)\n",
        "fusion_results = list(set(results_vector['documents'][0] + results_bm25))\n",
        "retrieved_context = \" \".join(fusion_results)\n",
        "\n",
        "# ================= GEMINI PARA RESPUESTA FINAL ==================\n",
        "response = model.generate_content(\n",
        "    f\"BasÃ¡ndote en el siguiente contexto (resultado de fusiÃ³n de mÃºltiples recuperadores), responde la pregunta y aÃ±ade explicaciÃ³n:\\n\\n{retrieved_context}\\n\\nPregunta: {query}\"\n",
        ")\n",
        "\n",
        "\n",
        "response_no_context = model.generate_content(\n",
        "    f\"BasÃ¡ndote en el siguiente contexto (resultado de fusiÃ³n de mÃºltiples recuperadores), responde la pregunta y aÃ±ade explicaciÃ³n:\\n\\nPregunta: {query}\"\n",
        ")\n",
        "\n",
        "response_chat = \"\"\"El cientÃ­fico que propuso un modelo atÃ³mico en 1913 fue Niels Bohr\n",
        "\n",
        "Bohr planteÃ³ que los electrones no podÃ­an ocupar cualquier Ã³rbita alrededor del nÃºcleo, sino que se encontraban en niveles de energÃ­a cuantizados. Esto significaba que los electrones solo podÃ­an moverse entre niveles discretos, emitiendo o absorbiendo energÃ­a en forma de cuantos (fotones). Su modelo fue una mejora respecto al de Rutherford, ya que explicaba fenÃ³menos como el espectro del hidrÃ³geno, donde las lÃ­neas de emisiÃ³n correspondÃ­an a transiciones electrÃ³nicas entre estos niveles.\n",
        "\n",
        "Este aporte fue crucial porque introdujo el concepto de cuantizaciÃ³n al modelo atÃ³mico, conectando las ideas de Planck y Einstein con la estructura de la materia, y sentando las bases de la mecÃ¡nica cuÃ¡ntica moderna.\"\"\"\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada con FusionRAG:\")\n",
        "print(response.text)\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada por Gemini sin contexto:\")\n",
        "print(response_no_context.text)\n",
        "\n",
        "\n",
        "print(\"\\nğŸ”¹ Respuesta generada por Chatgpt:\")\n",
        "print(response_chat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MÃ©tricas de evaluaciÃ³n"
      ],
      "metadata": {
        "id": "Gn0flFdbSin2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========= 8. COMPARACIÃ“N E INTERPRETACIÃ“N DE RESULTADOS =========\n",
        "\n",
        "print(\"\\n=== ComparaciÃ³n e InterpretaciÃ³n de las MÃ©tricas ===\")\n",
        "\n",
        "print(\"\\nComparando las respuestas generadas con la referencia (ChatGPT):\")\n",
        "\n",
        "bue_score_context, rouge_score_context = evaluate_response(response, response_chat)\n",
        "bue_score_no_context, rouge_score_no_context = evaluate_response_no_context(response_no_context, response_chat)\n",
        "\n",
        "# Compare BLEU scores\n",
        "print(\"\\nResultados BLEU:\")\n",
        "print(f\"- Gemini con contexto (BLEU): {bleu_score_context['bleu']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (BLEU): {bleu_score_no_context['bleu']:.4f}\")\n",
        "\n",
        "if bleu_score_context['bleu'] > bleu_score_no_context['bleu']:\n",
        "    print(\"  -> SegÃºn el BLEU score general, la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif bleu_score_context['bleu'] < bleu_score_no_context['bleu']:\n",
        "     print(\"  -> SegÃºn el BLEU score general, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los BLEU scores generales son similares.\")\n",
        "\n",
        "print(\"\\nResultados ROUGE:\")\n",
        "print(f\"- Gemini con contexto (ROUGE-1): {rouge_score_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-1): {rouge_score_no_context['rouge1']:.4f}\")\n",
        "print(f\"- Gemini con contexto (ROUGE-L): {rouge_score_context['rougeL']:.4f}\")\n",
        "print(f\"- Gemini sin contexto (ROUGE-L): {rouge_score_no_context['rougeL']:.4f}\")\n",
        "\n",
        "\n",
        "if rouge_score_context['rouge1'] > rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> SegÃºn ROUGE-1 (superposiciÃ³n de palabras individuales), la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif rouge_score_context['rouge1'] < rouge_score_no_context['rouge1']:\n",
        "    print(\"  -> SegÃºn ROUGE-1, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "    print(\"  -> Los ROUGE-1 scores son similares.\")\n",
        "\n",
        "if rouge_score_context['rougeL'] > rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> SegÃºn ROUGE-L (subsecuencia mÃ¡s larga, sensible al orden), la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\")\n",
        "elif rouge_score_context['rougeL'] < rouge_score_no_context['rougeL']:\n",
        "    print(\"  -> SegÃºn ROUGE-L, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\")\n",
        "else:\n",
        "     print(\"  -> Los ROUGE-L scores son similares.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwRd99o-RHQz",
        "outputId": "34ec9378-c607-4ee2-f619-44f225223b1a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ComparaciÃ³n e InterpretaciÃ³n de las MÃ©tricas ===\n",
            "\n",
            "Comparando las respuestas generadas con la referencia (ChatGPT):\n",
            "\n",
            "ğŸ”¹ BLEU score (Gemini with context): 0.0502\n",
            "ğŸ”¹ BLEU precision scores (Gemini with context):\n",
            "- Precision@1: 0.6154\n",
            "- Precision@2: 0.2745\n",
            "- Precision@3: 0.1600\n",
            "- Precision@4: 0.1020\n",
            "\n",
            "ğŸ”¹ ROUGE score (Gemini with context):\n",
            "- rouge1: 0.3854\n",
            "- rouge2: 0.2000\n",
            "- rougeL: 0.2188\n",
            "- rougeLsum: 0.2812\n",
            "\n",
            "ğŸ”¹ BLEU score (Gemini without context): 0.1580\n",
            "\n",
            "ğŸ”¹ ROUGE score (Gemini without context):\n",
            "- rouge1: 0.5051\n",
            "- rouge2: 0.2405\n",
            "- rougeL: 0.3276\n",
            "- rougeLsum: 0.3823\n",
            "\n",
            "Resultados BLEU:\n",
            "- Gemini con contexto (BLEU): 0.0904\n",
            "- Gemini sin contexto (BLEU): 0.0896\n",
            "  -> SegÃºn el BLEU score general, la respuesta de Gemini con contexto es mÃ¡s similar a la referencia.\n",
            "\n",
            "Resultados ROUGE:\n",
            "- Gemini con contexto (ROUGE-1): 0.3854\n",
            "- Gemini sin contexto (ROUGE-1): 0.5051\n",
            "- Gemini con contexto (ROUGE-L): 0.2188\n",
            "- Gemini sin contexto (ROUGE-L): 0.3276\n",
            "  -> SegÃºn ROUGE-1, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\n",
            "  -> SegÃºn ROUGE-L, la respuesta de Gemini sin contexto es mÃ¡s similar a la referencia.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "jd0d13ZvGXGW",
        "iyQtSj8YhcW3"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}