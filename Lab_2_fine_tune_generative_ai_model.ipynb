{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armandoordonez/GenAI/blob/main/Lab_2_fine_tune_generative_ai_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzpMK6XbV7aR",
        "tags": []
      },
      "source": [
        "# Fine-Tune un modelo de Gen AI Model para res√∫menes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObK2CXbTV7aT"
      },
      "source": [
        "En este cuaderno, se har√° en fine-tune de un LLM existente de Hugging Face para mejorar el resumen de los di√°logos. Utilizar√° el modelo [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5), que proporciona un modelo tuneado con instrucciones de alta calidad y puede resumir texto. Para mejorar las inferencias, se usar√° full fine-tuning y evaluar√° los resultados con m√©tricas de ROUGE. Luego, se usar√° Parameter Efficient Fine-Tuning (PEFT), evaluar√° el modelo resultante y ver√° que los beneficios de PEFT superan las desventajas de rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE1nZWSwV7aU"
      },
      "source": [
        "# Tabla de contenido"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuYTKFgPV7aU",
        "tags": []
      },
      "source": [
        "- [ 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM](#1)\n",
        "  - [ 1.1 - Set up Kernel and Required Dependencies](#1.1)\n",
        "  - [ 1.2 - Load Dataset and LLM](#1.2)\n",
        "  - [ 1.3 - Test the Model with Zero Shot Inferencing](#1.3)\n",
        "- [ 2 - Perform Full Fine-Tuning](#2)\n",
        "  - [ 2.1 - Preprocess the Dialog-Summary Dataset](#2.1)\n",
        "  - [ 2.2 - Fine-Tune the Model with the Preprocessed Dataset](#2.2)\n",
        "  - [ 2.3 - Evaluate the Model Qualitatively (Human Evaluation)](#2.3)\n",
        "  - [ 2.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#2.4)\n",
        "- [ 3 - Perform Parameter Efficient Fine-Tuning (PEFT)](#3)\n",
        "  - [ 3.1 - Setup the PEFT/LoRA model for Fine-Tuning](#3.1)\n",
        "  - [ 3.2 - Train PEFT Adapter](#3.2)\n",
        "  - [ 3.3 - Evaluate the Model Qualitatively (Human Evaluation)](#3.3)\n",
        "  - [ 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#3.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qBL7hyyV7aV"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Kz9rI8NxZcRd",
        "outputId": "d52722c3-4894-41ef-95c8-9465b6fdff1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.11\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.2.2 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install transformers==4.42.4\n",
        "!pip install datasets==2.19.1\n",
        "!pip install evaluate==0.4.5\n",
        "!pip install peft==0.10.0\n",
        "!pip install accelerate==0.30.0\n",
        "!pip install safetensors==0.4.2\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozxAGaY0iRvw",
        "outputId": "7b835bfe-5b9d-4418-aebe-2bcb476810ca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.12/dist-packages (2.2.2+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.17.2+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.2.2+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2) (2024.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: transformers==4.42.4 in /usr/local/lib/python3.12/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (0.35.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (0.4.2)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.42.4) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.4) (2024.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.4) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.4) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.42.4) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.42.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.42.4) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.42.4) (2025.8.3)\n",
            "Requirement already satisfied: datasets==2.19.1 in /usr/local/lib/python3.12/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (3.12.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.19.1) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.19.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.21.2->datasets==2.19.1) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.19.1) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.19.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.19.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets==2.19.1) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==2.19.1) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.1) (1.17.0)\n",
            "Requirement already satisfied: evaluate==0.4.5 in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.5) (2024.3.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (0.35.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate==0.4.5) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (0.7)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (3.12.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate==0.4.5) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate==0.4.5) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.5) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.5) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.5) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.5) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.5) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.5) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.5) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.5) (1.17.0)\n",
            "Requirement already satisfied: peft==0.10.0 in /usr/local/lib/python3.12/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (2.2.2+cpu)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (0.30.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from peft==0.10.0) (0.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2024.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (1.1.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.10.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft==0.10.0) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers->peft==0.10.0) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
            "Requirement already satisfied: accelerate==0.30.0 in /usr/local/lib/python3.12/dist-packages (0.30.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (2.2.2+cpu)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (0.35.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.30.0) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==0.30.0) (2024.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.30.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.30.0) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->accelerate==0.30.0) (1.1.10)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.30.0) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->accelerate==0.30.0) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch>=1.10.0->accelerate==0.30.0) (1.3.0)\n",
            "Requirement already satisfied: safetensors==0.4.2 in /usr/local/lib/python3.12/dist-packages (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Imports principales\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    GenerationConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"üîç Verificaci√≥n de versiones:\")\n",
        "print(f\"torch: {torch.__version__}\")\n",
        "import transformers, datasets, peft\n",
        "print(f\"transformers: {transformers.__version__}\")\n",
        "print(f\"datasets: {datasets.__version__}\")\n",
        "print(f\"evaluate: {evaluate.__version__}\")\n",
        "print(f\"peft: {peft.__version__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB_0VS8GimZ_",
        "outputId": "d2ef4ef8-e721-4709-ea58-55c9bf0d5747"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Verificaci√≥n de versiones:\n",
            "torch: 2.2.2+cpu\n",
            "transformers: 4.42.4\n",
            "datasets: 2.19.1\n",
            "evaluate: 0.4.5\n",
            "peft: 0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_gewrrkZcRe",
        "outputId": "eaad12c7-260d-48dc-f715-d5e7cefd9560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Package(s) not found: loralib\u001b[0m\u001b[33m\n",
            "\u001b[0mName: torch\n",
            "Version: 2.2.2+cpu\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchdata, torchvision\n",
            "---\n",
            "Name: torchdata\n",
            "Version: 0.11.0\n",
            "Summary: Composable data loading modules for PyTorch\n",
            "Home-page: https://github.com/pytorch/data\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: requests, torch, urllib3\n",
            "Required-by: torchtune\n",
            "---\n",
            "Name: transformers\n",
            "Version: 4.42.4\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers\n",
            "---\n",
            "Name: datasets\n",
            "Version: 2.19.1\n",
            "Summary: HuggingFace community-driven open-source library of datasets\n",
            "Home-page: https://github.com/huggingface/datasets\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: thomas@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyarrow-hotfix, pyyaml, requests, tqdm, xxhash\n",
            "Required-by: evaluate, torchtune\n",
            "---\n",
            "Name: evaluate\n",
            "Version: 0.4.5\n",
            "Summary: HuggingFace community-driven open-source library of evaluation\n",
            "Home-page: https://github.com/huggingface/evaluate\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: leandro@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: datasets, dill, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, requests, tqdm, xxhash\n",
            "Required-by: \n",
            "---\n",
            "Name: rouge_score\n",
            "Version: 0.1.2\n",
            "Summary: Pure python implementation of ROUGE-1.5.5.\n",
            "Home-page: https://github.com/google-research/google-research/tree/master/rouge\n",
            "Author: Google LLC\n",
            "Author-email: rouge-opensource@google.com\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: absl-py, nltk, numpy, six\n",
            "Required-by: \n",
            "---\n",
            "Name: peft\n",
            "Version: 0.10.0\n",
            "Summary: Parameter-Efficient Fine-Tuning (PEFT)\n",
            "Home-page: https://github.com/huggingface/peft\n",
            "Author: The HuggingFace team\n",
            "Author-email: sourab@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: accelerate, huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch, tqdm, transformers\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show torch torchdata transformers datasets evaluate rouge_score loralib peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCWW6dCxZcRf",
        "outputId": "7729d91c-8ba7-45e7-c3ba-b459681925c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ T5 funciona: Hallo Welt\n"
          ]
        }
      ],
      "source": [
        "# verificar que transformers funciona\n",
        "\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Probar con el modelo m√°s peque√±o\n",
        "\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Test b√°sico\n",
        "input_text = \"translate English to Spanish: Hello world\"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "outputs = model.generate(input_ids, max_length=20)\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(f\"‚úÖ T5 funciona: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV0mclXEV7aV"
      },
      "source": [
        "<a name='1.1'></a>\n",
        "### 1.1 - Set up Kernel and Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pFVij_p3V7aX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Importe los componentes necesarios.\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtIOTMkrV7aX",
        "tags": []
      },
      "source": [
        "<a name='1.2'></a>\n",
        "### 1.2 - Cargar Dataset y LLM\n",
        "\n",
        "[DialogSum](https://huggingface.co/datasets/knkarthick/dialogsum) es un dataset de Hugging Face. contiene 10,000+ dialogos con los correspondientes res√∫menes y temas etiquetados manualmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hmH9Or7RV7aY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdiC8pFxZcRg",
        "outputId": "4156d594-6cf5-4e54-8d80-0f910086cd5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'article': Value(dtype='string', id=None), 'highlights': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None)}\n"
          ]
        }
      ],
      "source": [
        "print(dataset[\"train\"].features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBsjjW4OV7aY",
        "tags": []
      },
      "source": [
        "Load the pre-trained [FLAN-T5 model](https://huggingface.co/docs/transformers/model_doc/flan-t5) and its tokenizer directly from HuggingFace. Notice that you will be using the [small version](https://huggingface.co/google/flan-t5-base) of FLAN-T5. Setting `torch_dtype=torch.bfloat16` specifies the memory type to be used by this model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "SsEMZw1CV7aY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Cargamos el modelo y el tokenizador\n",
        "\n",
        "model_name='google/flan-t5-small'\n",
        "# model_name='t5-base'\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir7FTf20V7aY",
        "tags": []
      },
      "source": [
        "Es posible extraer la cantidad de par√°metros del modelo y descubrir cu√°ntos de ellos se pueden entrenar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dYnW_pqiV7aY",
        "outputId": "5678c2f6-6f01-4d59-f977-09dba3606489",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parametros entrenables del modelo: 76,961,152\n",
            " Total de parametros del modelo: 76,961,152\n",
            " Porcentaje de parametros entrenables 100%\n"
          ]
        }
      ],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"Parametros entrenables del modelo: {trainable_model_params:,.0f}\\n Total de parametros del modelo: {all_model_params:,.0f}\\n Porcentaje de parametros entrenables {100 * trainable_model_params / all_model_params:.0f}%\"\n",
        "#print(f'El area es: {area:,.2f}')\n",
        "print(print_number_of_trainable_model_parameters(original_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbNtotpbV7aZ",
        "tags": []
      },
      "source": [
        "<a name='1.3'></a>\n",
        "### 1.3 - Prueba del modelo con Zero Shot Inferencing\n",
        "\n",
        "Pruebe el modelo con la inferencia de tiro cero. Puede ver que el modelo tiene dificultades para resumir el di√°logo en comparaci√≥n con el resumen de referencia, pero extrae informaci√≥n importante del texto que indica que el modelo se puede ajustar a la tarea en cuesti√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ruNKVIGEV7aZ",
        "outputId": "a99248d6-8fab-48b2-df6c-9d25b323f70f",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            " PROMPT DE ENTRADA:\n",
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "(CNN)Former New England Patriots star Aaron Hernandez will need to keep his lawyers even after being convicted of murder and other charges in the death of Odin Lloyd. The 25-year-old potentially faces three more trials -- one criminal and two civil actions. Next up is another murder trial in which he is accused of killing two men and wounding another person near a Boston nightclub in July 2012. Prosecutors have said Hernandez fatally shot Daniel de Abreu and Safiro Furtado when he fired into their 2003 BMW.  Another passenger was wounded and two others were uninjured. Hernandez pleaded not guilty at his arraignment. The trial was originally slated for May 28, but Jake Wark, spokesman for the Suffolk County District Attorney's Office, said Wednesday the trial had been postponed and no new date had been set. \"We expect to select a new court date in the coming days and then set the amended trial track. The Suffolk indictments allege two counts of first-degree murder for the July 16, 2012, shooting deaths of Daniel de Abreu and Safiro Furtado in Boston's South End; three counts of armed assault with intent to murder and one count of assault and battery by means of a dangerous weapon for shots fired at three surviving victims; and one count of unlawful possession of a firearm,\" he said. The families of de Abreu and Furtado filed civil suits against Hernandez, and a judge froze his $5 million in assets, pending the outcome of the double-murder trial. The freeze includes the disputed $3.3 million signing bonus payment Hernandez claims he is owed by the New England Patriots. Hernandez is also being sued by a man who claims Hernandez shot him while they were in a limousine in Miami in February 2013. Alexander Bradley claims the then-New England Patriot tight end wounded him after the two got into a fight at a Miami strip club. In a lawsuit filed four months later, Bradley said Hernandez fired at him during a limo ride after leaving the club and that Hernandez intentionally \"possessed a gun which he was not legally licensed to have.\" Hernandez's lawyers have argued he couldn't defend himself properly while on trial in Massachusetts. There was no criminal charge in the case. And then there is the grievance over unpaid bonus money filed by the NFL players union on behalf of Hernandez, who signed a contract in 2012 that potentially was worth more than $40 million. If the grievance is heard by the league, Hernandez will be represented by the the National Football League Players' Association. Who was Odin Lloyd? CNN's Lawrence Crook contributed to this report.\n",
            "\n",
            "Summary:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESUMEN HUMANO (BASELINE) :\n",
            "Aaron Hernandez has been found guilty in Odin Lloyd's death, but his troubles are not over .\n",
            "He also faces murder charges in Suffolk County, Massachusetts, but trial was postponed .\n",
            "In addition, Hernandez will face two civil lawsuits; one is in relation to Suffolk County case .\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "RESUMEN GENERADO POR EL MODELO CON ZERO SHOT:\n",
            "Aaron Hernandez will be arraigned on Wednesday, but he will not be able to return to court.\n"
          ]
        }
      ],
      "source": [
        "index = 200\n",
        "\n",
        "dialogue = dataset['test'][index]['article']\n",
        "summary = dataset['test'][index]['highlights']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    original_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=200,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f' PROMPT DE ENTRADA:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'RESUMEN HUMANO (BASELINE) :\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'RESUMEN GENERADO POR EL MODELO CON ZERO SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-zTt-k9V7aZ",
        "tags": []
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2 - Realizar Full Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7EhKQABV7aZ",
        "tags": []
      },
      "source": [
        "<a name='2.1'></a>\n",
        "### 2.1 - Preprocesar el dataset Dialog-Summary\n",
        "\n",
        "Se necesita convertir los pares dialogo-resumen (prompt-response) en instrucciones expl√≠citas para el LLM. Agregar una instrucci√≥n al inicio del dialogo como `Summarize the following conversation` y al inicio del resumen agregar `Summary`como se muestra a continuaci√≥n:\n",
        "\n",
        "Training prompt (dialogue):\n",
        "```\n",
        "Summarize the following conversation.\n",
        "\n",
        "    Chris: This is his part of the conversation.\n",
        "    Antje: This is her part of the conversation.\n",
        "    \n",
        "Summary:\n",
        "```\n",
        "\n",
        "Training response (summary):\n",
        "```\n",
        "Both Chris and Antje participated in the conversation.\n",
        "```\n",
        "\n",
        "Then preprocess the prompt-response dataset into tokens and pull out their `input_ids` (1 per token)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kQd6neWAV7aZ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    start_prompt = 'Summarize the following article.\\n\\n'\n",
        "    end_prompt = '\\n\\nSummary: '\n",
        "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"article\"]]\n",
        "    print(\"Size of prompt list: \", len(prompt))  # Imprimir el tama√±o de la lista\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = tokenizer(example[\"highlights\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    return example\n",
        "\n",
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'article', 'highlights',])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI8F0UXeZcRi",
        "outputId": "da3e1a30-44a9-4b63-eaee-02bdac1c2bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.dataset_dict.DatasetDict'>\n",
            "Dataset({\n",
            "    features: ['input_ids', 'labels'],\n",
            "    num_rows: 1\n",
            "})\n",
            "[[8929, 16023, 2213, 4173, 6324, 12591, 15, 2347, 3996, 1755, 329, 13462, 38, 3, 88, 5050, 507, 2089, 3, 5, 5209, 7556, 845, 3, 88, 65, 150, 1390, 12, 9030, 17, 449, 112, 1723, 550, 3, 5, 6324, 12591, 15, 31, 7, 8783, 45, 166, 874, 16023, 4852, 43, 118, 1213, 16, 2019, 3069, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ],
      "source": [
        "print (type(tokenized_datasets))\n",
        "first_example = tokenized_datasets[\"train\"].select([0])\n",
        "print(first_example)\n",
        "print(first_example['labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8HypBOxV7aa",
        "tags": []
      },
      "source": [
        "Para ahorrar algo de tiempo en el laboratorio, submuestrear√° el conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "S2qI0XRXV7aa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcZHpjXiV7aa",
        "tags": []
      },
      "source": [
        "Compruebe las formas de las tres partes del conjunto de datos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Zzg-w16UV7aa",
        "outputId": "10d52aaa-e4f4-4260-d424-6b4650ffa3bf",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the datasets:\n",
            "Training: (2872, 2)\n",
            "Validation: (134, 2)\n",
            "Test: (115, 2)\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 2872\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 134\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 115\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shapes of the datasets:\")\n",
        "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
        "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
        "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
        "\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4sYS5pDV7aa"
      },
      "source": [
        "El dataset de salida esta listo para el fine-tunning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg2hlvGiV7aa"
      },
      "source": [
        "<a name='2.2'></a>\n",
        "### 2.2 - Aplicar Fine -Tunning para el modelo con el dataset Preprocesado\n",
        "\n",
        "Ahora utilice la clase integrada \"Trainer\" de Hugging Face (consulte la documentaci√≥n [aqui](https://huggingface.co/docs/transformers/main_classes/trainer)). Pase el conjunto de datos preprocesado con referencia al modelo original. Los dem√°s par√°metros de entrenamiento se encuentran experimentalmente y no es necesario profundizar en ellos por el momento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "YnVXOApPV7aa",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db727699-1771-4d76-e8bb-05f93592cc5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "output_dir = f'./article-summary-training-{str(int(time.time()))}'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=1e-5,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=1,\n",
        "    max_steps=1\n",
        ")\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=original_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKNYWu0uV7ab",
        "tags": []
      },
      "source": [
        "Start training process...\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi4gUGxlYXNlIGJlIHBhdGllbnQuPC90ZXh0PgogICAgPHRleHQgeD0iMTAwIiB5PSI1NiIgZm9udC1mYW1pbHk9IkFyaWFsLCBzYW5zLXNlcmlmIiBmb250LXNpemU9IjE0IiBmaWxsPSIjMzMzMzMzIj5Zb3UgY2FuIHNhZmVseSBpZ25vcmUgdGhlIHdhcm5pbmcgbWVzc2FnZXMuPC90ZXh0Pgo8L3N2Zz4K\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xL-BFJRiV7ab",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#trainer.train()\n",
        "#Entrenar una versi√≥n completamente tuneada  del modelo toma  horas en una GPU. Para ahorrar tiempo, se puede descargar un punto de control del modelo completamente ajustado para utilizarlo en el resto del notebook The size of the downloaded instruct model is approximately 1GB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4gDo7HUV7ac",
        "tags": []
      },
      "source": [
        "Create an instance of the `AutoModelForSeq2SeqLM` class for the instruct model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkapq1TaV7ab"
      },
      "source": [
        "Entrenar una versi√≥n completamente tuneada  del modelo toma  horas en una GPU. Para ahorrar tiempo, se puede descargar un punto de control del modelo completamente ajustado para utilizarlo en el resto del notebook The size of the downloaded instruct model is approximately 1GB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "0yXVvL57V7ac",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Esto se usa cuando se descarga el modelo de un bucket de S3\n",
        "# !aws s3 cp --recursive s3://dlai-generative-ai/models/flan-dialogue-summary-checkpoint/ ./flan-dialogue-summary-checkpoint/\n",
        "#!ls -alh ./flan-dialogue-summary-checkpoint/pytorch_model.bin\n",
        "#instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"./flan-dialogue-summary-checkpoint\", torch_dtype=torch.bfloat16)\n",
        "\n",
        "# Este chekpoint del modelo se descarga de Hugging Face\n",
        "instruct_model_name='./article-summary-training-1758573709/checkpoint-1'\n",
        "instruct_model = AutoModelForSeq2SeqLM.from_pretrained( instruct_model_name, torch_dtype=torch.bfloat16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "U0x74Z2ZV7ac",
        "tags": [],
        "outputId": "136a77ea-1786-4b58-a951-5c25bf653373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.models.t5.modeling_t5.T5ForConditionalGeneration"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>transformers.models.t5.modeling_t5.T5ForConditionalGeneration</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/transformers/models/t5/modeling_t5.py</a>T5 Model with a `language modeling` head on top.\n",
              "\n",
              "The T5 model was proposed in [Exploring the Limits of Transfer Learning with a Unified Text-to-Text\n",
              "Transformer](https://arxiv.org/abs/1910.10683) by Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan\n",
              "Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu. It&#x27;s an encoder decoder transformer pre-trained in a\n",
              "text-to-text denoising generative setting.\n",
              "\n",
              "This model inherits from [`PreTrainedModel`]. Check the superclass documentation for the generic methods the\n",
              "library implements for all its model (such as downloading or saving, resizing the input embeddings, pruning heads\n",
              "etc.)\n",
              "\n",
              "This model is also a PyTorch [torch.nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) subclass.\n",
              "Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage\n",
              "and behavior.\n",
              "\n",
              "Parameters:\n",
              "    config ([`T5Config`]): Model configuration class with all the parameters of the model.\n",
              "        Initializing with a config file does not load the weights associated with the model, only the\n",
              "        configuration. Check out the [`~PreTrainedModel.from_pretrained`] method to load the model weights.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1544);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "\n",
        "type(instruct_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHeExNydV7am"
      },
      "source": [
        "<a name='2.3'></a>\n",
        "### 2.3 - Evaluar el modelo cualitativamente (evaluaci√≥n humana)\n",
        "\n",
        "Como ocurre con muchas aplicaciones GenAI, un enfoque cualitativo en el que uno se hace la pregunta \"¬øMi modelo se comporta como se supone que debe hacerlo\" suele ser un buen punto de partida. En el siguiente ejemplo , puede ver c√≥mo el modelo ajustado es capaz de crear un resumen razonable del di√°logo en comparaci√≥n con la incapacidad original de comprender lo que se le pide al modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "oqUEQycEV7an",
        "outputId": "773ab3dd-815f-42c7-9246-4ee4eb75899d",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "RESUMEN HUMANO (BASELINE):\n",
            "Aaron Hernandez has been found guilty in Odin Lloyd's death, but his troubles are not over .\n",
            "He also faces murder charges in Suffolk County, Massachusetts, but trial was postponed .\n",
            "In addition, Hernandez will face two civil lawsuits; one is in relation to Suffolk County case .\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODELO ORIGINAL:\n",
            "Aaron Hernandez is a New England Patriots star who was convicted of murder and other charges in the death of Odin Lloyd.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL CON INSTRUCCIONES:\n",
            "Aaron Hernandez is facing a double-murder trial in the death of a New England Patriots star.\n"
          ]
        }
      ],
      "source": [
        "index = 200\n",
        "dialogue = dataset['test'][index]['article']\n",
        "human_baseline_summary = dataset['test'][index]['highlights']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following article.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'RESUMEN HUMANO (BASELINE):\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'MODELO ORIGINAL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'MODEL CON INSTRUCCIONES:\\n{instruct_model_text_output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nVduwEAV7an"
      },
      "source": [
        "<a name='2.4'></a>\n",
        "### 2.4 - Evaluar el modelo cuantitativamente (con la m√©trica ROUGE)\n",
        "\n",
        "[ROUGE metric](https://en.wikipedia.org/wiki/ROUGE_(metric)) Ayuda a cuantificar la validez de los res√∫menes generados por los modelos. Compara los res√∫menes con un resumen de referencia, generalmente creado por un usuario. Si bien no es perfecto, indica el aumento general en la eficacia del resumen que hemos logrado mediante el ajuste."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAEGGxUwqjri",
        "outputId": "3edca3e1-1a43-47cf-c431-1181c78692cb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "qau_WJrhV7an",
        "tags": []
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVqXw8-QV7an"
      },
      "source": [
        "Genere las salidas para la muestra del conjunto de datos de prueba (solo 10 di√°logos y res√∫menes para ahorrar tiempo) y guarde los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wbLNwQHAV7an",
        "outputId": "176ce5b4-7355-4241-c068-6e60c16efde9",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  Membership gives the ICC jurisdiction over all...   \n",
              "1  Theia, a bully breed mix, was apparently hit b...   \n",
              "2  Mohammad Javad Zarif has spent more time with ...   \n",
              "3  17 Americans were exposed to the Ebola virus w...   \n",
              "4  Student is no longer on Duke University campus...   \n",
              "5  College-bound basketball star asks girl with D...   \n",
              "6  Amnesty's annual death penalty report catalogs...   \n",
              "7  Andrew Getty's death appears to be from natura...   \n",
              "8  Once a super typhoon, Maysak is now a tropical...   \n",
              "9  Bob Barker returned to host \"The Price Is Righ...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0  The Palestinian Authority has officially forma...   \n",
              "1  Theia, a stray dog, has been buried in a field...   \n",
              "2  Mohammad Javad Zarif is the Iranian foreign mi...   \n",
              "3  A Nebraska Medicine spokesman says five Americ...   \n",
              "4  Duke University has admitted to hanging a noos...   \n",
              "5  Trey Moses and Ellie Meredith were invited to ...   \n",
              "6  Amnesty International says it is \"shocking\" th...   \n",
              "7  Andrew Getty, 47, has a net worth of $2.1 bill...   \n",
              "8  Tropical storm Maysak is expected to make land...   \n",
              "9  Bob Barker, who hosted \"Lucky Seven\" for the f...   \n",
              "\n",
              "                            instruct_model_summaries  \n",
              "0  The Palestinian Authority has officially forma...  \n",
              "1  Theia, a stray dog, has been buried in a field...  \n",
              "2  Mohammad Javad Zarif is the Iranian foreign mi...  \n",
              "3  A Nebraska Medicine spokesman says five Americ...  \n",
              "4  Duke University has admitted to hanging a noos...  \n",
              "5  Trey Moses and Ellie Meredith were invited to ...  \n",
              "6  Amnesty International says it is \"shocking\" th...  \n",
              "7  Andrew Getty, 47, has a net worth of $2.1 bill...  \n",
              "8  Tropical storm Maysak is expected to make land...  \n",
              "9  Bob Barker, who hosted \"Lucky Seven\" for the f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e4e26bc-8ff0-499f-8617-2a41c3161ea4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>instruct_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
              "      <td>The Palestinian Authority has officially forma...</td>\n",
              "      <td>The Palestinian Authority has officially forma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
              "      <td>Theia, a stray dog, has been buried in a field...</td>\n",
              "      <td>Theia, a stray dog, has been buried in a field...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
              "      <td>Mohammad Javad Zarif is the Iranian foreign mi...</td>\n",
              "      <td>Mohammad Javad Zarif is the Iranian foreign mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
              "      <td>A Nebraska Medicine spokesman says five Americ...</td>\n",
              "      <td>A Nebraska Medicine spokesman says five Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Student is no longer on Duke University campus...</td>\n",
              "      <td>Duke University has admitted to hanging a noos...</td>\n",
              "      <td>Duke University has admitted to hanging a noos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>College-bound basketball star asks girl with D...</td>\n",
              "      <td>Trey Moses and Ellie Meredith were invited to ...</td>\n",
              "      <td>Trey Moses and Ellie Meredith were invited to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Amnesty's annual death penalty report catalogs...</td>\n",
              "      <td>Amnesty International says it is \"shocking\" th...</td>\n",
              "      <td>Amnesty International says it is \"shocking\" th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Andrew Getty's death appears to be from natura...</td>\n",
              "      <td>Andrew Getty, 47, has a net worth of $2.1 bill...</td>\n",
              "      <td>Andrew Getty, 47, has a net worth of $2.1 bill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Once a super typhoon, Maysak is now a tropical...</td>\n",
              "      <td>Tropical storm Maysak is expected to make land...</td>\n",
              "      <td>Tropical storm Maysak is expected to make land...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bob Barker returned to host \"The Price Is Righ...</td>\n",
              "      <td>Bob Barker, who hosted \"Lucky Seven\" for the f...</td>\n",
              "      <td>Bob Barker, who hosted \"Lucky Seven\" for the f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e4e26bc-8ff0-499f-8617-2a41c3161ea4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e4e26bc-8ff0-499f-8617-2a41c3161ea4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e4e26bc-8ff0-499f-8617-2a41c3161ea4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4a65be3b-2f15-4b86-8253-acace6e0f2c7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a65be3b-2f15-4b86-8253-acace6e0f2c7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4a65be3b-2f15-4b86-8253-acace6e0f2c7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_46b4867d-872a-43e9-9d7e-608560fffc1a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_46b4867d-872a-43e9-9d7e-608560fffc1a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"human_baseline_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Once a super typhoon, Maysak is now a tropical storm with 70 mph winds .\\nIt could still cause flooding, landslides and other problems in the Philippines .\",\n          \"Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\\n\\\"She's a true miracle dog and she deserves a good life,\\\" says Sara Mellado, who is looking for a home for Theia .\",\n          \"College-bound basketball star asks girl with Down syndrome to high school prom .\\nPictures of the two during the \\\"prom-posal\\\" have gone viral .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Tropical storm Maysak is expected to make landfall Sunday morning on the southeastern coast of Isabela province and be out of the Philippines by Monday.\",\n          \"Theia, a stray dog, has been buried in a field in Washington state for the first time since the death of a stray dog.\",\n          \"Trey Moses and Ellie Meredith were invited to Eastern High School's prom.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruct_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Tropical storm Maysak is expected to make landfall Sunday morning on the southeastern coast of Isabela province and be out of the Philippines by Monday.\",\n          \"Theia, a stray dog, has been buried in a field in Washington state for the first time since the death of a stray dog.\",\n          \"Trey Moses and Ellie Meredith were invited to Eastern High School's prom.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "dialogues = dataset['test'][0:10]['article']\n",
        "human_baseline_summaries = dataset['test'][0:10]['highlights']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "\n",
        "for _, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following article.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "\n",
        "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1sn5m_RV7ao",
        "tags": []
      },
      "source": [
        "Eval√∫e los modelos que calculan las m√©tricas ROUGE. ¬°Observe la mejora en los resultados!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VOEdyCI6V7ao",
        "outputId": "3a42c45a-9802-426c-a5d8-09593d2afefd",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.26206689932347876, 'rouge2': 0.08510117850943891, 'rougeL': 0.2222768275252066, 'rougeLsum': 0.2413939727972234}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': 0.25144555821755754, 'rouge2': 0.07844037347442087, 'rougeL': 0.20918622005762388, 'rougeLsum': 0.2299722229491326}\n"
          ]
        }
      ],
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DgC5fcUV7ao",
        "tags": []
      },
      "source": [
        "The results show substantial improvement in all ROUGE metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "phafOHqFV7ao",
        "outputId": "e523ea83-cc18-4049-f0a9-da8113f934a5",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\n",
            "rouge1: -1.06%\n",
            "rouge2: -0.67%\n",
            "rougeL: -1.31%\n",
            "rougeLsum: -1.14%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\")\n",
        "\n",
        "improvement = (np.array(list(instruct_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(instruct_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aBoXNXzV7ap"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Fine tunning Eficiente de Par√°metros (PEFT)\n",
        "\n",
        "Ahora, realicemos un ajuste fino **PEFT** en lugar del ajuste fino completo, como se hizo anteriormente. PEFT es una forma de ajuste fino de instrucciones mucho m√°s eficiente que el ajuste fino completo, con resultados de evaluaci√≥n comparables, como ver√° pronto.\n",
        "\n",
        "PEFT es un t√©rmino gen√©rico que incluye **Adaptaci√≥n de Bajo Rango (LoRA)** y ajuste de prompts (¬°que NO ES LO MISMO que ingenier√≠a de prompts!). En la mayor√≠a de los casos, cuando alguien habla de PEFT, se refiere a LoRA. LoRA, a un nivel muy alto, permite al usuario ajustar su modelo utilizando menos recursos computacionales (en algunos casos, una sola GPU). Despu√©s del ajuste fino para una tarea, caso de uso o inquilino espec√≠fico con LoRA, el resultado es que el LLM original permanece sin cambios y surge un nuevo \"adaptador LoRA\". Este adaptador LoRA es mucho m√°s peque√±o que el LLM original: aproximadamente un porcentaje de un solo d√≠gito del tama√±o del LLM original (MB vs. GB).\n",
        "\n",
        "No obstante, en el momento de la inferencia, el adaptador LoRA debe reunirse y combinarse con su LLM original para atender la solicitud de inferencia. La ventaja, sin embargo, es que muchos adaptadores LoRA pueden reutilizar el LLM original, lo que reduce los requisitos generales de memoria al atender m√∫ltiples tareas y casos de uso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9hjS-tsV7ap"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "\n",
        "\n",
        "### 3.1 - Configuraci√≥n del modelo PEFT/LoRA para el ajuste fino\n",
        "\n",
        "Debe configurar el modelo PEFT/LoRA para el ajuste fino con un nuevo adaptador de capa/par√°metro. Al usar PEFT/LoRA, se congela el LLM subyacente y solo se entrena el adaptador. Observe la configuraci√≥n de LoRA a continuaci√≥n. Observe el hiperpar√°metro de rango (`r`), que define el rango/dimensi√≥n del adaptador que se va a entrenar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "iOjoDSwWV7ap",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMIM04QQV7ap",
        "tags": []
      },
      "source": [
        "Add LoRA adapter layers/parameters to the original LLM to be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "LnFsAZn-V7aq",
        "outputId": "79ca1f0b-90a8-4e9a-ac15-e95c0a3b17f3",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parametros entrenables del modelo: 1,376,256\n",
            " Total de parametros del modelo: 78,337,408\n",
            " Porcentaje de parametros entrenables 2%\n"
          ]
        }
      ],
      "source": [
        "peft_model = get_peft_model(original_model,\n",
        "                            lora_config)\n",
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_ONKxTAV7aq",
        "tags": []
      },
      "source": [
        "<a name='3.2'></a>\n",
        "### 3.2 - Train PEFT Adapter\n",
        "\n",
        "Define training arguments and create `Trainer` instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "CN-Dbz23V7aq",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3b7d0d-d005-4d4a-896b-67d07152b431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "output_dir = f'./peft-dialogue-article-training-{str(int(time.time()))}'\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=1,\n",
        "    max_steps=1\n",
        ")\n",
        "\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHBCtG41V7aq"
      },
      "source": [
        "Now everything is ready to train the PEFT adapter and save the model.\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "DpmZQBsMV7aq",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "cca5ac5e-069f-4d3d-d80b-8065f9864048"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>39.750000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./peft-dialogue-article-checkpoint-local/tokenizer_config.json',\n",
              " './peft-dialogue-article-checkpoint-local/special_tokens_map.json',\n",
              " './peft-dialogue-article-checkpoint-local/spiece.model',\n",
              " './peft-dialogue-article-checkpoint-local/added_tokens.json',\n",
              " './peft-dialogue-article-checkpoint-local/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "peft_trainer.train()\n",
        "peft_model_path=\"./peft-dialogue-article-checkpoint-local\"\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3voqLpwV7aq",
        "tags": []
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6G7nD1SV7aq",
        "tags": []
      },
      "source": [
        "That training was performed on a subset of data. To load a fully trained PEFT model, read a checkpoint of a PEFT model from S3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzVDgXwAV7aq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#!aws s3 cp --recursive s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/ ./peft-dialogue-summary-checkpoint-from-s3/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbW58BYaV7ar",
        "tags": []
      },
      "source": [
        "Comprueba que el tama√±o de este modelo es mucho menor que el LLM original:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "C2LTOlgbV7ar",
        "outputId": "6a3f7778-b539-4247-fe64-c7f6295676f9",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dir: cannot access '/a': No such file or directory\n",
            "dir: cannot access '.contentpeft-dialogue-article-training-1758583404checkpoint-1': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!dir /a .\\content\\peft-dialogue-article-training-1758583404\\checkpoint-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "886lESmdV7ar",
        "tags": []
      },
      "source": [
        "Prepare este modelo a√±adiendo un adaptador al modelo FLAN-T5 original. Est√° configurando `is_trainable=False` porque el plan es realizar inferencia √∫nicamente con este modelo PEFT. Si estuviera preparando el modelo para entrenamiento posterior, deber√≠a configurar `is_trainable=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "5FCVCdu8V7ar",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
        "                                       './peft-dialogue-article-training-1758583404/checkpoint-1',\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       is_trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uretNB0sV7ar",
        "tags": []
      },
      "source": [
        "The number of trainable parameters will be `0` due to `is_trainable=False` setting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "HqWoJBCrV7ar",
        "outputId": "1e49288e-0b3a-45f4-f4fb-68c58d2193bc",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parametros entrenables del modelo: 0\n",
            " Total de parametros del modelo: 78,337,408\n",
            " Porcentaje de parametros entrenables 0%\n"
          ]
        }
      ],
      "source": [
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywXzSfTrV7ar"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "### 3.3 - Evaluate the Model Qualitatively (Human Evaluation)\n",
        "\n",
        "Make inferences for the same example as in sections [1.3](#1.3) and [2.3](#2.3), with the original model, fully fine-tuned and PEFT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Cpcpbtj1V7as",
        "outputId": "c3f0a018-fc1f-4a20-ad11-7d51e1208d16",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "Aaron Hernandez has been found guilty in Odin Lloyd's death, but his troubles are not over .\n",
            "He also faces murder charges in Suffolk County, Massachusetts, but trial was postponed .\n",
            "In addition, Hernandez will face two civil lawsuits; one is in relation to Suffolk County case .\n",
            "---------------------------------------------------------------------------------------------------\n",
            "ORIGINAL MODEL:\n",
            "Hernandez's lawyer says he will be arraigned in the trial of the New England Patriots.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INSTRUCT MODEL:\n",
            "Aaron Hernandez will be arraigned on Wednesday, but he will not be able to return to court.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "PEFT MODEL: Aaron Hernandez will be arraigned on Wednesday, but he will not be able to return to court.\n"
          ]
        }
      ],
      "source": [
        "index = 200\n",
        "dialogue = dataset['test'][index]['article']\n",
        "baseline_human_summary = dataset['test'][index]['highlights']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'PEFT MODEL: {peft_model_text_output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waRMtMeRV7as"
      },
      "source": [
        "<a name='3.4'></a>\n",
        "### 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)\n",
        "Perform inferences for the sample of the test dataset (only 10 dialogues and summaries to save time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "gVyu4NbDV7as",
        "outputId": "85534023-a0c2-4634-f395-ee0fe11cc2e5",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  Membership gives the ICC jurisdiction over all...   \n",
              "1  Theia, a bully breed mix, was apparently hit b...   \n",
              "2  Mohammad Javad Zarif has spent more time with ...   \n",
              "3  17 Americans were exposed to the Ebola virus w...   \n",
              "4  Student is no longer on Duke University campus...   \n",
              "5  College-bound basketball star asks girl with D...   \n",
              "6  Amnesty's annual death penalty report catalogs...   \n",
              "7  Andrew Getty's death appears to be from natura...   \n",
              "8  Once a super typhoon, Maysak is now a tropical...   \n",
              "9  Bob Barker returned to host \"The Price Is Righ...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0  The Palestinians signed the Rome Statute in Ja...   \n",
              "1  Theia is a stray dog, and a dog named Theia is...   \n",
              "2  The two men, who have been a member of the Ira...   \n",
              "3  Five Americans who were exposed to Ebola have ...   \n",
              "4  Duke University is investigating a student who...   \n",
              "5  Trey and Ellie Meredith are both excited about...   \n",
              "6  Amnesty estimates that at least a quarter of p...   \n",
              "7  Andrew Getty, grandson of J. Paul Getty, was f...   \n",
              "8  Tropical storm Maysak has been a major threat ...   \n",
              "9  Bob Barker, who hosted the show for the first ...   \n",
              "\n",
              "                            instruct_model_summaries  \\\n",
              "0  The Palestinian Authority has officially forma...   \n",
              "1  Theia, a stray dog, has been buried in a field...   \n",
              "2  Mohammad Javad Zarif is the Iranian foreign mi...   \n",
              "3  A Nebraska Medicine spokesman said five Americ...   \n",
              "4  Duke University has admitted to hanging a noos...   \n",
              "5  Trey Moses and Ellie Meredith were invited to ...   \n",
              "6  Amnesty International says it is \"shocking\" th...   \n",
              "7  Andrew Getty, 47, has a net worth of $2.1 bill...   \n",
              "8  Tropical storm Maysak is expected to make land...   \n",
              "9  Bob Barker, who hosted \"The Price Is Right\" fo...   \n",
              "\n",
              "                                peft_model_summaries  \n",
              "0  The Palestinian Authority has officially becom...  \n",
              "1  Theia, a stray dog, has been buried in a field...  \n",
              "2  Mohammad Javad Zarif is the Iranian foreign mi...  \n",
              "3  A Nebraska Medicine spokesman said five Americ...  \n",
              "4  Duke University has admitted to hanging a noos...  \n",
              "5  Trey Moses and Ellie Meredith were invited to ...  \n",
              "6  Amnesty International says it is \"shocking\" th...  \n",
              "7  Andrew Getty, 47, has a net worth of $2.1 bill...  \n",
              "8  Tropical storm Maysak is expected to make land...  \n",
              "9  Bob Barker, who hosted \"Lucky Seven\" for the f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f892c6df-1b54-4dfc-98d7-a50aad8dcd3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>instruct_model_summaries</th>\n",
              "      <th>peft_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Membership gives the ICC jurisdiction over all...</td>\n",
              "      <td>The Palestinians signed the Rome Statute in Ja...</td>\n",
              "      <td>The Palestinian Authority has officially forma...</td>\n",
              "      <td>The Palestinian Authority has officially becom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Theia, a bully breed mix, was apparently hit b...</td>\n",
              "      <td>Theia is a stray dog, and a dog named Theia is...</td>\n",
              "      <td>Theia, a stray dog, has been buried in a field...</td>\n",
              "      <td>Theia, a stray dog, has been buried in a field...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mohammad Javad Zarif has spent more time with ...</td>\n",
              "      <td>The two men, who have been a member of the Ira...</td>\n",
              "      <td>Mohammad Javad Zarif is the Iranian foreign mi...</td>\n",
              "      <td>Mohammad Javad Zarif is the Iranian foreign mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17 Americans were exposed to the Ebola virus w...</td>\n",
              "      <td>Five Americans who were exposed to Ebola have ...</td>\n",
              "      <td>A Nebraska Medicine spokesman said five Americ...</td>\n",
              "      <td>A Nebraska Medicine spokesman said five Americ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Student is no longer on Duke University campus...</td>\n",
              "      <td>Duke University is investigating a student who...</td>\n",
              "      <td>Duke University has admitted to hanging a noos...</td>\n",
              "      <td>Duke University has admitted to hanging a noos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>College-bound basketball star asks girl with D...</td>\n",
              "      <td>Trey and Ellie Meredith are both excited about...</td>\n",
              "      <td>Trey Moses and Ellie Meredith were invited to ...</td>\n",
              "      <td>Trey Moses and Ellie Meredith were invited to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Amnesty's annual death penalty report catalogs...</td>\n",
              "      <td>Amnesty estimates that at least a quarter of p...</td>\n",
              "      <td>Amnesty International says it is \"shocking\" th...</td>\n",
              "      <td>Amnesty International says it is \"shocking\" th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Andrew Getty's death appears to be from natura...</td>\n",
              "      <td>Andrew Getty, grandson of J. Paul Getty, was f...</td>\n",
              "      <td>Andrew Getty, 47, has a net worth of $2.1 bill...</td>\n",
              "      <td>Andrew Getty, 47, has a net worth of $2.1 bill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Once a super typhoon, Maysak is now a tropical...</td>\n",
              "      <td>Tropical storm Maysak has been a major threat ...</td>\n",
              "      <td>Tropical storm Maysak is expected to make land...</td>\n",
              "      <td>Tropical storm Maysak is expected to make land...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bob Barker returned to host \"The Price Is Righ...</td>\n",
              "      <td>Bob Barker, who hosted the show for the first ...</td>\n",
              "      <td>Bob Barker, who hosted \"The Price Is Right\" fo...</td>\n",
              "      <td>Bob Barker, who hosted \"Lucky Seven\" for the f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f892c6df-1b54-4dfc-98d7-a50aad8dcd3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f892c6df-1b54-4dfc-98d7-a50aad8dcd3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f892c6df-1b54-4dfc-98d7-a50aad8dcd3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f6b91433-b7a3-4015-b843-3515f41f11da\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6b91433-b7a3-4015-b843-3515f41f11da')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f6b91433-b7a3-4015-b843-3515f41f11da button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c9678ef8-3861-43f5-9eb2-f5d6d590434e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c9678ef8-3861-43f5-9eb2-f5d6d590434e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"human_baseline_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Once a super typhoon, Maysak is now a tropical storm with 70 mph winds .\\nIt could still cause flooding, landslides and other problems in the Philippines .\",\n          \"Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field .\\n\\\"She's a true miracle dog and she deserves a good life,\\\" says Sara Mellado, who is looking for a home for Theia .\",\n          \"College-bound basketball star asks girl with Down syndrome to high school prom .\\nPictures of the two during the \\\"prom-posal\\\" have gone viral .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Tropical storm Maysak has been a major threat to the Philippines, the Philippines and other major cities.\",\n          \"Theia is a stray dog, and a dog named Theia is a cat.\",\n          \"Trey and Ellie Meredith are both excited about the prom.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruct_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Tropical storm Maysak is expected to make landfall Sunday morning on the southeastern coast of Isabela province and be out of the Philippines by Monday.\",\n          \"Theia, a stray dog, has been buried in a field in Washington State for the last time.\",\n          \"Trey Moses and Ellie Meredith were invited to Eastern High School's prom.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"peft_model_summaries\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Tropical storm Maysak is expected to make landfall Sunday morning on the southeastern coast of Isabela province and be out of the Philippines by Monday.\",\n          \"Theia, a stray dog, has been buried in a field in Washington State for the last time.\",\n          \"Trey Moses and Ellie Meredith were invited to Eastern High School's prom.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "dialogues = dataset['test'][0:10]['article']\n",
        "human_baseline_summaries = dataset['test'][0:10]['highlights']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "peft_model_summaries = []\n",
        "\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    human_baseline_text_output = human_baseline_summaries[idx]\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "    peft_model_summaries.append(peft_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries, peft_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries', 'peft_model_summaries'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRaiIUisZcRv"
      },
      "source": [
        "\n",
        "Calcule la puntuaci√≥n ROUGE para este subconjunto de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "-3HrajATV7as",
        "outputId": "0c942b78-b7ca-4cda-f2f2-394941bbb239",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.2549182893986622, 'rouge2': 0.07356904328215805, 'rougeL': 0.1972108520475721, 'rougeLsum': 0.2069255714007535}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': 0.25595289956907474, 'rouge2': 0.09781080267246764, 'rougeL': 0.22994217104051826, 'rougeLsum': 0.24145730805173746}\n",
            "PEFT MODEL:\n",
            "{'rouge1': 0.25656234742991624, 'rouge2': 0.08334320341709506, 'rougeL': 0.22416459104409153, 'rougeLsum': 0.23662839385575674}\n"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4mO5W3cV7at"
      },
      "source": [
        "Notice, that PEFT model results are not too bad, while the training process was much easier!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjF00HfCV7at"
      },
      "source": [
        "The results show less of an improvement over full fine-tuning, but the benefits of PEFT typically outweigh the slightly-lower performance metrics.\n",
        "\n",
        "Calculate the improvement of PEFT over the original model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "pIjy_UjPV7at",
        "outputId": "4883e62f-58d5-499c-f5c2-fbf781653b2c",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\n",
            "rouge1: 0.16%\n",
            "rouge2: 0.98%\n",
            "rougeL: 2.70%\n",
            "rougeLsum: 2.97%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOAnR7g0V7at"
      },
      "source": [
        "Now calculate the improvement of PEFT over a full fine-tuned model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "vi4WUIjGV7at",
        "outputId": "949d5214-4704-4aa6-c582-36f5706f3d41",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\n",
            "rouge1: 0.06%\n",
            "rouge2: -1.45%\n",
            "rougeL: -0.58%\n",
            "rougeLsum: -0.48%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(instruct_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgcIK1u4V7au"
      },
      "source": [
        "Here you see a small percentage decrease in the ROUGE metrics vs. full fine-tuned. However, the training requires much less computing and memory resources (often just a single GPU)."
      ]
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "colab": {
      "provenance": []
    },
    "instance_type": "ml.m5.2xlarge",
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}